\chapter{Voorstellen voor verdere optimalisaties}

In dit hoofdstuk bespreken we de verdere optimalisaties die nog kunnen (en moeten) gebeuren om de \nwmretriever{} op grote schaal te kunnen inzetten.
De belangrijkste optimalisatie wellicht die nog moet gebeuren is het gebruik van bulk inserts bij het wegschrijven van de opgehaalde resultaten in de databank.
Ook bij het beheer van de retrieverthreads is er nog ruimte voor verbetering.


\section{Bulk inserts bij databankinteracties}

De databankinteracties werden uitvoerig besproken in de \cref{werking,profiling,impact-db}.
Een verdere optimalisatie die zeker nog gedaan moet worden,
is het gebruik van bulk inserts bij het wegschrijven van de opgehaalde gegevens in de databank.

In \cref{impact-db} hebben we gezien dat het wegschrijven van de gegevens in de databank een gigantische impact heeft op de uitvoeringstijd,
dat alleen maar toeneemt met het aantal te bevragen toestellen.
Het bevragen van slechts 100 toestellen ging zonder het wegschrijven van de resultaten maar liefst 61 keer sneller.
Sterker nog, de impact van de databankinteracties is zodanig groot dat de performantiewinst van de andere optimalisaties bijna teniet gedaan wordt.
De nieuwe versie was bij 100 toestellen slechts 5\% sneller dan de oude, maar ruim zeven keer sneller als de gegevens niet weggeschreven moesten worden.
Het implementeren van bulk inserts is dus absoluut cruciaal om de \nwmretriever{} succesvol te kunnen inzetten op grote schaal.

Het implementeren van bulk requests hoeft zelfs niet zoveel werk en tijd te vereisen.
Een eenvoudige implementatie houdt een globale tabel bij in het geheugen die de resultaten tijdelijk bijhoudt.
De InsertResultRow-methode wordt dan aangepast om de gegevens in die tabel in het geheugen weg te schrijven in plaats van rechtstreeks in de databank.
Eenmaal een bepaalde hoeveelheid gegevens in de databank weggeschreven zijn kan de InsertResultRow-methode dan beslissen om al die data
in een keer weg te schrijven in de databank met dus een bulk insert.

Het nadeel van deze manier van werken is dat het wegschrijven van de resultaten in dezelfde thread gebeurt als het bevragen van een toestel.
Als de gegevens weggeschreven worden zal die thread en het bevragen van dat ene toestel een stuk langer duren dan anders.
Een andere manier van werken die wat meer arbeidsintensief is en meer tijd vraagt werd ook al voorgesteld in \cref{impact-db}.

Daarbij wordt de verantwoordelijkheid van het wegschrijven van de resultaten in de databank overgeheveld naar een aparte thread.
Deze zal dan instaan om, wanneer de tabel in het geheugen een bepaalde hoeveelheid gegevens bevat de gegevens weg te schrijven naar de databank,
zonder de andere retrieverthreads daarbij te storen.
De InsertResultRow-methode is dan enkel nog verantwoordelijk voor het wegschrijven van de gegevens in de tabel in het geheugen.

Men kan dan nagaan of het beter is om periodiek gegevens weg te schrijven tijdens het bevragen van de toestellen,
of om de gegevens ineens weg te schrijven na het bevragen van de toestellen, of naar het einde toe als het aantal retrieverthreads daalt.

De gegevens hoeven zelfs niet weggeschreven te worden in een databank.
Men kan verschillende implementaties voorzien die de tabel in het geheugen op verschillende manieren verwerkt.
Men kan er bijvoorbeeld ook voor kiezen om de gegevens naar een bestand weg te schrijven of een combinatie.
Het grote voordeel is dat het opslaan van de gegevens los staat van het opvragen ervan, dus dat de snelheidsimpact ervan beperkt blijft.


\section{Dynamisch threadbeheer}

Het beheer van threads en het CPU-gebruik werden besproken in \cref{werking,cpu-gebruik}.

Er was al gebleken dat het beheer van de threads in de originele versie van de \nwmretriever{} beter kon.
Het probleem was dat er gewacht werd tot de eerst gestarte thread klaar was alvorens nieuwe threads aan te maken voor het bevragen van toestellen.
Dat leidde tot korte periodes waarbij het aantal retrieverthreads zakte en er geen neiuwe threads werden aangemaakt.
Maar zoals gezegd werd dit probleem reeds aangepakt door NetwerkMining tijdens de masterproef en
wordt er gebruik gemaakt van een andere implementatie in de nieuwe versies van de \nwmretriever{}.

We hebben ook gezien dat het aantal threads vaststond op 50 threads.
Een betere manier van werken zou het aantal threads dynamisch bepalen aan de hand van de beschikbare resources (zowel CPU-, RAM- als bandbreedtegebruik).
Uit de tests in \cref{benchmarks-geheugengebruik,benchmarks-bandbreedte} bleek echter dat het geheugen- en bandbreedtegebruik beperkt blijft
en er dus meer dan genoeg reserve over is voor die resources.
Het aantal threads zou dus voornamelijk afhangen van het CPU-gebruik.

Op de server van de Virtual Wall was er nog een overschot aan CPU-rekenkracht,
maar het omgekeerde is ook mogelijk.
Bij een tekort aan rekenkracht heeft het geen zin om meer threads aan te maken en kan het mogelijk zelfs een averechts effect hebben.

Het dynamisch beheren van threads is een algemeen probleem waar veel softwareprojecten mee geconfronteerd worden.
Gelukkig betekent dit ook dat er reeds vele oplossingen voor zijn ontwikkeld die vrij te gebruiken zijn.
Het .NET-platform biedt hiervoor een eigen oplossing onder de vorm van de \gls{tpl} sinds versie 4 van het .NET-framework.

Het doel van \gls{tpl} is om het ontwikkelaars gemakkelijker te maken om gebruik te maken van parallelisme en multithreading in applicaties.
\Gls{tpl} schaalt dynamisch de mate van parallelisme om zo efficiënt mogelijk gebruik te maken van alle processorcores die beschikbaar zijn.
\Gls{tpl} verzorgt ook het inplannen van threads in een \textit{thread pool}, ondersteuning voor het annuleren van threads, toestandbeheer en
andere low-level details\cite{msdn-tpl}.


\section{Intelligentie}

Op langere termijn kan de software voorzien worden van enige intelligentie bij het opvragen van netwerkinformatie.
Sommige gegevens zijn namelijk zeer dynamisch zijn terwijl andere gegevens quasi statisch kunnen zijn.
Denk bijvoorbeeld aan temperatuurmetingen en een overzicht van alle netwerkinterfaces die aanwezig zijn in een toestel.
Het eerste gegeven verandert constant, het laatste haast nooit.
Het is dan ook logisch dat het laatste niet zo vaak opgevraagd moet worden als het eerste.
Zo zouden we kunnen een algoritme of heuristiek ontwikkelen die de veranderlijkheid van gegevens bepaalt en afhankelijk daarvan
beslist hoe vaak dat gegeven opgehaald moet worden.
Gegevens kunnen ook meer of minder belangrijk zijn als andere.
De netwerkbeheerder zou ook zelf kunnen de periodiciteit opgeven voor het opvragen van bepaalde gegevens,
afhankelijk van het belang dat de netwerkbeheerder eraan hecht.
Vooral als er historische data bijgehouden wordt is dit een interessante uitbreiding.


%\section{Mogelijke uitbreidingen}
%\todo[inline]{
%Misschien lager in de scriptie plaatsen vermits de uitbreidingen niet geïmplementeerd zijn.
%Misschien meer naar het einde toe...}
%
%Als uitbreiding kan de bestaande software voorzien worden van enige intelligentie bij het opvragen van netwerkinformatie.
%Het is zo dat sommige gegevens zeer dynamisch zijn maar andere gegevens kunnen quasi statisch zijn.
%Denk bijvoorbeeld aan temperatuurmetingen en een overzicht van alle netwerkinterfaces die aanwezig zijn in een toestel.
%Het eerste gegeven verandert constant, het laatste haast nooit.
%Het is dan ook logisch dat het laatste niet zo vaak opgevraagd moet worden als het eerste.
%Zo zouden we kunnen een algoritme of heuristiek ontwikkelen die de veranderlijkheid van gegevens bepaalt en afhankelijk daarvan
%beslist hoe vaak dat gegeven opgehaald moet worden.
%Gegevens kunnen ook meer of minder belangrijk zijn als andere.
%De netwerkbeheerder zou dan ook zelf kunnen de periodiciteit opgeven voor het opvragen van bepaalde gegevens,
%afhankelijk van het belang dat de netwerkbeheerder eraan hecht.
%Ook voor het bijhouden van historische data kan dit een interessante optie zijn.
%
%Een ander idee is om te zien of de netwerkcomponenten SNMP-requests beantwoorden die via broadcast of
%multicast (na het inschrijven op een multicastgroep) verstuurd zijn geweest.
%Bij Linux machines is dit bijvoorbeeld wel het geval.
%Hierdoor zou het netwerkverkeer om SNMP informatie te verzamelen quasi gehalveerd kunnen worden.
%De SNMP retriever moet niet meer elk netwerkelement individueel ondervragen maar ondervraagt ze allemaal tegelijkertijd.
%Het netwerkvolume dat gegenereerd wordt door de netwerkcomponenten als antwoord blijft wel even groot,
%en afhankelijk van de omvang van het netwerk zou dit ook wel eens een zeer zware belasting voor de retriever kunnen zijn.
%De SNMP-retriever moet dan tenslotte de antwoorden van alle netwerkelementen tegelijkertijd kunnen verwerken. %TODO: wordflow met vorige zin
%Toch is het zeker een optie die de moeite waard is om te onderzoeken.
%Er moet dan ook gekeken worden wat voor aanpassingen er nodig zijn aan het netwerk om dit te ondersteunen:
%het inschrijven van de nodes op een multicastgroep, het toestaan van het routeren van multicastverkeer op de routers en het voorzien van bijhorende multicastroutes.

