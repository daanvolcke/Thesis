\chapter{Benchmarks en Experimenten}
% \chaptermark{Een kortere titel voor de paginahoofding (verschillend van titel in TOC)}

\todo[inline,caption={}]{Terminologie?

\begin{itemize}
	\item Object (geretourneerde gegevens.) <-> OID's (kunnen subtakken zijn van meerdere OID's)
	\item SNMP Data Retriever
	\item Relevante OID's/objecten/gegevens
\end{itemize}

}

\section{Kleinschalige benchmarks en experimenten}

\todo[inline]{Inleiding. Kort uitleggen wat we allemaal doen in deze sectie.}

\todo[inline]{Eigenlijk maakt het weinig uit om wat voor soort toestellen het gaat:
alhoewel de applicatie voornamelijk bedoeld is voor netwerkapparatuur, voor onze testen hebben we enkel een noodzaak aan voldoende gegevens die via SNMP kunnen opgevraagd worden.}

\subsection{VirtualBox}
\label{virtualbox}

\todo[inline]{Betere titel! Virtuele testopstelling van een handvol switches.}

\todo[inline, caption={}]{
Bespreking originele testopstelling van Wouter Tavernier? \\
Specs \\
Software(config)

\begin{itemize}
	\item screen (niet geinstalleerd)
	\item sudo
	\item snmpd
	\item snmp
	\item snmp-mibs-downloader
	\item bridge, lldp...
\end{itemize}


}

De eerste testopstelling bestaat uit vier virtuele machines die switches in een netwerk nabootsen.
Als virtualisatieplatform wordt er gebruik gemaakt van \textit{Oracle VM VirtualBox} (verder gewoon VirtualBox genoemd).
VirtualBox is vrij te verkrijgen voor alle gangbare besturingssystemen en is bovendien open-source.

\subsubsection{Hardwareconfiguratie}

Het gastheerbesturingssysteem is een 64-bit versie van Windows 7.
Windows en VirtualBox zijn geïnstalleerd op een SSD, maar de virtuele machines zelf staan op een magnetische harde schijf.

Aan elke node wordt 256 MB geheugen en een CPU kern (van een Intel Core i7 3610QM processor) toegewezen.
Op de nodes wordt een minimale versie van Debian 7 geïnstalleerd, zonder grafische schil.
Hierdoor is zelfs 256 MB een ruime luxe voor de nodes: na het opstarten van een node wordt er amper 70MB geheugen gebruikt.

Alle toestellen zijn rechtstreeks met elkaar verbonden in een privénetwerk.
Via \gls{nat} kunnen ze via de gastheer toch nog het internet bereiken.
Dit werd bewerkstelligd met de \textit{NAT Network mode},
een nieuwe feature in VirtualBox die nog niet in de documentatie staat maar wel kort beschreven wordt in een nieuwspost (zie\cite{vbox-nat-network-mode}).
Ter vergelijking:
\textit{NAT mode} laat gastsystemen toe om met het internet te communiceren via \gls{nat} maar zitten elk in een apart privénetwerk en kunnen dus niet met elkaar praten.
\textit{Host-only mode} laat gastsystemen met elkaar (en het gastheersysteem) communiceren door ze in een gezamelijk privénetwerk te plaatsen, 
maar communicatie met het internet is niet mogelijk.

\subsubsection{Softwareconfiguratie}

Hieronder leggen we kort stap voor stap uit hoe je op een Debianinstallatie de nodige SNMP software kunt installeren en configureren.
De uitleg is zeer is zeer beknopt gehouden en dient enkel om je op weg te helpen.
In de testopstelling werden de nodes ook nog geconfigureerd als switches die het \gls{stp} draaien alsook het \gls{lldp}.
Deze extra protocollen bieden informatie aan die via SNMP opgevraagd kan worden en zijn ook gegevens die in een realistische situatie opgevraagd kunnen worden.
De configuratie als switch en van LLDP wordt hier echter niet besproken. \todo{Dit kan eventueel als bijlage uitgelegd worden.}

Zoals gezegd worden alle nodes voorzien van een minimale Debian 7 installatie.
Dit wil zeggen dat er geen extra softwarepakketten worden geselecteerd bij installatie.

In de veronderstelling dat het internet werkt beginnen we na de installatie met het updaten van het systeem en het installeren van \textit{sudo}:

\begin{lstlisting}[language=bash]
# apt-get update
# apt-get upgrade
# apt-get install sudo
\end{lstlisting}

Maak een gebruiker aan en zorg ervoor dat je sudo rechten hebt met behulp van het \textit{visudo} commando of door je gebruiker toe te voegen aan de \textit{sudo} groep.

\begin{lstlisting}[language=bash]
# visudo
# usermod -a -G sudo <jouw gebruikersnaam>
\end{lstlisting}

Dan installeren we de snmp \textit{daemon} die zal antwoorden op SNMP requests.
Om te testen is het ook interessant om de client-side SNMP tools te installeren alsook een tool om de belangrijkste \glspl{mib} te downloaden.
Met die \glspl{mib} worden numerieke \glspl{oid} omgezet naar de leesbare tekstuele voorstelling.

Debian laat standaard niet toe dat niet-vrije (non-free) software\footnote{
	Dit is software die niet volledig vrij is maar op een of andere manier beperkt wordt door zijn licentie. De eisen die gesteld worden aan vrije software voor Debian zijn te vinden in de Debian Free Software Guidelines (DFSG)\cite{dfsg}\cite{dfsg-wiki}.}
geïnstalleerd wordt. De \textit{snmp-mibs-downloader} tool is daar een voorbeeld van.
Om dit toch toe te laten moet je voor elke lijn in /etc/apt/sources.list het non-free component achteraan toevoegen.
Dan krijg je zoiets:

\begin{lstlisting}[language=bash]
deb http://ftp.belnet.be/debian wheezy main non-free
deb-src http://ftp.belnet.be/debian wheezy main non-free
\end{lstlisting}

Nu kunnen we wel snmp-mibs-downloader en de andere tools installeren.

\begin{lstlisting}[language=bash]
$ sudo apt-get install snmpd snmp snmp-mibs-downloader
\end{lstlisting}

Het volgende commando zal de \glspl{mib} downloaden:

\begin{lstlisting}[language=bash]
$ sudo download-mibs
\end{lstlisting}

Het gebruik van de \glspl{mib} kun je aanzetten door de volgende regel in commentaar te zetten in het bestand /etc/snmp/snmp.conf:

\begin{lstlisting}[language=bash]
mibs :
\end{lstlisting}

Om \textit{snmpd} te configureren kun je gebruik maken van het \textit{snmpconf} commando die op interactieve wijze configuratiebestanden aanmaakt.
We moeten ook nog de locatie van de \gls{mib}-bestanden opgeven. Voeg daarom het volgende toe aan /etc/default/snmpd:

\begin{lstlisting}[language=bash]
export MIBS=/usr/share/mibs
\end{lstlisting}

Vervolgens herstarten we snmpd om de nieuwe configuratie in te laden.

\begin{lstlisting}[language=bash]
$ sudo /etc/init.d/snmpd restart
\end{lstlisting}

We kunnen testen of alles werkt met het volgende:

\begin{lstlisting}[language=bash]
$ snmpwalk -v1 -cpublic localhost mib-2
\end{lstlisting}

\todo[inline]{Verder eventueel: bridge configuratie, LLDP}

\todo[inline]{SNMP Data Retriever in een Windows XP VM?}

\todo[inline]{\LARGE {Effectieve testen mbv VirtualBox VM's}}

\todo[inline, caption={}]{Tests in VirtualBox:

\begin{itemize}
	\item Aantal SNMP objecten onder de voornaamste OID's versus het totaal aantal objecten (snmp-objecten.pl) \\
		Vergelijking tussen de verschillende iMinds switchen wat betreft aantal objecten (vergelijkfracties.pl) \\
		Zie pg.7, verslag week 9-10
	\item Reactietijd: tijd per object, SNMP walk vs bulk (verschillende groottes)
	\item SNMP Data Retriever vs. Net-SNMP
\end{itemize}

}


\subsection{Productieswitches}

\todo[inline]{Betere titel? Fysieke "testopstelling" van een handvol switches. Niet echt een testopstelling natuurlijk, maar wel echte productieswitches.}

Naast een viertal virtuele machines kunnen we ook gebruik maken van tien productieswitches die deel uitmaken van het netwerk van iMinds.
Deze switches kunnen we gebruiken om na te gaan of de tests met de virtuele machines de realiteit goed kunnen benaderen.
Er worden drie verschillende modellen gebruikt, allen van HP: een 5412 zl, 4208 vl en acht ProCurve 2650 switches.
De grootste bevat bijna 300 poorten en bevat ook routerfunctionaliteiten.

\subsection{Netwerkvertraging}
\label{latency}

Netwerkvertraging of \textit{latency} definiëren we als de zogenaamde \textit{round-trip time},
of de tijd die nodig is om een bericht te sturen naar een ander toestel en voor die computer om het antwoord terug naar jou te sturen\footnote{
	Latency kan ook gedefiniëerd worden als enkel de tijd dat een bericht nodig heeft om in een richting reizen.
	Dat is echter moeilijker om te meten. Meestal hanteert men de round-trip time omdat dat gemeten kan worden vanaf slechts een punt. \cite{latency-wiki}
}.
De latency tussen twee toestellen kan je gemakkelijk meten vanop een van de twee toestellen met behulp van het \textit{ping} commando.

Op een LAN-netwerk bedraagt de latency gewoonlijk minder dan 1 ms en valt dus te verwaarlozen.
Vanaf dat verkeer over het internet gaat, gaat latency een grote rol spelen.
Zolang de afstand niet te lang is (als we binnen West-Europa blijven) dan blijft de latency beperkt tot 10-50 ms.
Als we daarentegen communiceren met bv. Amerika, dan spreken we al over 100-200 ms (afhankelijk of we spreken over de Oost- of Westkust).
Voor sommige toepassingen (zoals bijvoorbeeld real-time spellen) is dit te hoog om nog te gebruiken.

Het belang voor ons van de latency is voornamelijk bij het opvragen van veel gegevens met GET- en GETNEXT-requests.
Zoals uitgelegd in \cref{snmp-operaties} wordt er slechts een gegeven in een request gestopt en
moet je steeds wachten op het antwoord alvoren je de volgende request stuurt.
Als te maken hebt met een latency van zeg maar 25 ms, wil dat zeggen dat je steeds 25 ms moet wachten alvorens je de volgende request kunt sturen.
Stel dat je 200 gegevens wenst op te halen, dan doe je hier 5 seconden over (200 gegevens $*$ 25 ms wachten per gegeven).

Was er een netwerkvertraging van slechts 1 ms, dan zou het ophalen van dezelfde 200 gegevens slechts 200 ms duren.
Natuurlijk houden we hier nog geen rekening met de tijd die het toestel zelf nodig heeft om het bericht te verwerken en te antwoorden.

De originele versie van de SNMP Data Retriever maakte effectief gebruik van GET- en GETNEXT-requests.
Daarom hebben we hier enkele tests op gedaan om te zien of latency inderdaad een grote rol speelt in de tijd nodig om gegevens op te vragen.

\subsubsection{Meetresultaten}

Deze tests hebben we gedaan op de virtuele machines met Debian.
In Linux kun je gemakkelijk een artificiële netwerkvertraging creëren met het volgende commando:

\begin{lstlisting}[language=bash, caption={Artificiële netwerkvertraging van 25ms op de eth0 interface}]
$ sudo tc qdisc add dev eth0 root netem delay 25 ms
\end{lstlisting}

Dit zorgt ervoor dat er een latency van 25 ms gecreëerd wordt op de \textit{eth0} interface.
\todo[]{Is een vertraging van 25 ms wel realistisch?}
We hebben de test gedaan met de originele versie van de SNMP Data Retriever bij het ondervragen van 1 en 4 machines,
alsook bij een vertraging van 25 ms en zonder vertraging.
De volgende \glspl{oid} werden opgevraagd (in het XML formaat van SNMP Data Retriever, zie \cref{snmp-data-retriever-configuratie}),
goed voor ongeveer 217 gegevens per toestel:

\begin{lstlisting}[language=xml]
<snmpWalk oid="1.3.6.1.2.1.1" mib="RFC1213-MIB" name="system" />
<snmpWalk oid="1.3.6.1.2.1.2" mib="RFC1213-MIB" name="interfaces" />
<snmpWalk oid="1.3.6.1.2.1.4" mib="RFC1213-MIB" name="ip" />
<snmpWalk oid="1.3.6.1.2.1.17.1" mib="BRIDGE-MIB" name="dot1dBase" />
<snmpWalk oid="1.3.6.1.2.1.17.2" mib="BRIDGE-MIB" name="dot1dStp" />
\end{lstlisting}

De resultaten zie je in \cref{tabel-latency}.
Je ziet de gemiddelde uitvoeringstijd in ms van 10 iteraties.
Daaronder zie je ook het CPU-gebruik van het (volledige) systeem.

\begin{table}[h]
\centering
\begin{tabular}{@{}lllll@{}}
\toprule
                      & \multicolumn{2}{c}{25 ms vertraging} & \multicolumn{2}{c}{geen vertraging} \\
                      & 1 toestel       & 4 toestellen       & 1 toestel       & 4 toestellen      \\ \midrule
Gemiddelde tijd (ms): & 15.650          & 15.987             & 2.693           & 6.105             \\
CPU verbruik:         & 10\%            & 35\%               & 80-90\%         & \textbf{100\%}    \\ \bottomrule
\end{tabular}
\caption{De tijd nodig om 1-4 toestellen te ondervragen met en zonder vertraging}
\label{tabel-latency}
\end{table}

Jammer genoeg is de resolutie voor het meten van het CPU-gebruik beperkt tot 1 meting per seconde.
Desondanks is dat toch voldoende om te zien dat het CPU-gebruik een bottleneck is bij het bevragen van vier toestellen zonder vertraging.
Het moet wel gezegd worden dat het testsysteem waarop de retriever draaide een Windows XP virtuele machine was met slechts 1 CPU core toegewezen\footnote{
	Dit was omdat er een VirtualBox image werd voorzien waarop alles reeds voorgeconfigureerd was om snel te kunnen beginnen met testen van de retriever.
	Latere tests maken gebruik van Windows 7 en meerdere cores.
}.
Ook bij slechts een toestel zie je dat het CPU-gebruik vrij hoog ligt.
Wanneer we een vertraging van 25 ms introduceren is het CPU-gebruik een stuk lager.
Hadden we 50 toestellen bevraagd, het maximum aantal dat de retriever tegelijk doet, met een vertraging van 25 ms, dan hadden we evenwel weer in de problemen gezeten.

Hoe dan ook, de belangrijkste reden dat we deze test gedaan hebben is de impact op de uitvoeringstijd.
We zien dat het opvragen van iets meer dan 200 gegevens van een enkel toestel zonder vertraging geen 200 ms duurt zoals eerst berekend,
maar ongeveer 2700 ms.
We zaten er slechts een factor 10 naast.
Er is natuurlijk flink wat meer aan de hand dan enkel het vervoeren van het pakket over de netwerkverbinding.
De retriever doet namelijk ook een aantal databankinteracties zoals het aanmaken van tabellen en
het wegschrijven van de resultaten in die databank (zie \cref{snmp-data-retriever-db}).

Als we dan een vertraging van 25 ms invoeren neemt de uitvoeringstijd toe met bijna een factor 6.
Onze oververeenvoudigde rekensom van daarnet zou uitkomen op een kleine 6 seconden, de realiteit wijst uit dat het ruim 15 seconden duurt.

Dezelfde vergelijking maken met vier toestellen is jammer genoeg nutteloos vanwege de CPU-bottleneck.
Het is wel interessant om te zien dat het ondervragen van extra toestellen slechts een kleine impact heeft op de uitvoeringstijd.
Logisch, want de vier toestellen worden (gelukkig) tegelijkertijd ondervraagd.


\subsubsection{Conclusie}

Het is duidelijk dat de netwerkvertraging een belangrijke rol speelt in de uitvoeringstijd van de retriever.
We raden daarom dan ook sterk aan om, indien mogelijk, de bevragingen \textit{on-site} te doen
(dit wil zeggen op hetzelfde netwerk in plaats van op afstand) om de netwerkvertraging te minimaliseren.

We kunnen het effect van de netwerkvertraging ook beperken door het gebruik van GETBULK-requests,
waarbij we meteen meerdere gegevens in een pakket stoppen.
Als je 10 gegevens in een pakket stopt, betekent dat theoretisch al een snelheidwinst van factor 10.
We zullen dit dan ook verder onderzoeken in \cref{bulkrequests-benchmarks}.

\todo[inline]{Dubbelcheck of naar de correcte paragraaf verwezen wordt.
Latency komt wel niet opnieuw aan bod in die paragraaf, beter om de laatste zin hier te herschrijven om te zeggen dat we bulkrequests onderzoeken.}




\subsection{Filteren van de op te vragen gegevens}
\label{fracties}

Een van de vragen die we ons gesteld hebben, is of het wel degelijk de moeite waard is om gegevens te filteren?
Is het met andere woorden nuttig dat we ons bezighouden met een lijst op te stellen van enkel de \glspl{oid} die ons interesseren,
of kunnen we evengoed meteen alle gegevens opvragen die een SNMP agent ons aanbiedt?

\subsubsection{Meetresultaten}

Voor deze test stellen we een lijst op van \gls{oid} die ons interesseren en vergelijken we het aantal objecten dat dit oplevert
in vergelijking met het totaal aantal objecten dat een SNMP agent aanbiedt.
Omdat de virtuele machines die als switch geconfigureerd zijn niet zijn aangesloten op echte computers hebben ze ook maar weinig data.
Bovendien bevatten de virtuele machines omdat ze een gans besturingssysteem draaien heel wat extra informatie die een gewone switch niet heeft.
Denk hierbij aan bijvoorbeeld een lijst van alle geïnstalleerde softwarepakketten.
Anderzijds ontbreken de virtuele machines een aantal extra gegevens die producenten kunnen aanbieden zoals statistieken.
Omdat het belangrijk is dat deze test de realiteit zo goed mogelijk weergeeft,
werd deze test dan ook uitgevoerd op de productieswitches van iMinds.

Dit is de lijst van \glspl{oid} die we als interessant beschouwen:

\begin{lstlisting}
1.3.6.1.2.1.1			(system)
1.3.6.1.2.1.2			(interfaces)
1.3.6.1.2.1.4			(ip)
1.3.6.1.2.1.17.1 		(dot1dBase)
1.3.6.1.2.1.17.2		(dot1dStp)
1.0.8802.1.1.2.1.4.1	(lldpRemTable)
\end{lstlisting}

De \textit{dot1d} \glspl{oid} hebben betrekking op de switching functionaliteit.
\textit{dot1dBase} bevat onder andere de tabel met alle switchpoorten terwijl \textit{dot1dStp} informatie bevat over het Spanning Tree Protocol (STP).

Om te bepalen hoeveel objecten er in totaal aangeboden worden kun je een SNMP walk doen van \gls{oid} '.' of '.1'.

Een voorbeeld van de uitvoer die onze test levert is het volgende:

\begin{lstlisting}
Host: atlas1a1.intec.ugent.be
Date: Thu Apr 17 17:20:48 CEST 2014

Retrieved 267 objects for dot1dStp (1.3.6.1.2.1.17.2).
Retrieved 1318 objects for dot1dBase (1.3.6.1.2.1.17.1).
Retrieved 7943 objects for interfaces (1.3.6.1.2.1.2).
Retrieved 7 objects for system (1.3.6.1.2.1.1).
Retrieved 1716 objects for ip (1.3.6.1.2.1.4).
Retrieved 207 objects for lldpRemTable (1.0.8802.1.1.2.1.4.1).
Retrieved 11458 objects in total.
The agent has 369388 objects in total.
Percentage of retrieved objects from total: 3.10188744626247%
\end{lstlisting}

We zien dus hoeveel objecten we terugkrijgen bij het overlopen van elke \gls{oid},
het totaal aantal objecten we teruggekregen hebben bij alle voor ons interessante \glspl{oid} en
hoeveel objecten het toestal in totaal aanbiedt (voor alle ondersteunde \glspl{oid}).
Tenslotte zien we ook nog het percentage van interessante objecten t.o.v. het totaal.
Een samenvatting van de resultaten voor de verschillende switches zien we in \cref{tabel-fracties}.
Gemiddeld komen we uit op een percentage van 4,48\% interessante gegevens over alle switches heen.

\begin{table}[h]
\centering
\begin{tabular}{@{}lrrr@{}}
\toprule
Host                    & Interessante objecten & Totaal aantal objecten & Percentage \\ \midrule
atlas1a1.intec.ugent.be & 11.458                & 369.388                & 3,10\%     \\
atlas1a2.intec.ugent.be & 5.636                 & 123.617                & 4,56\%     \\
atlas2a1.intec.ugent.be & 3.247                 & 69.022                 & 4,70\%     \\
atlas2a2.intec.ugent.be & 3.238                 & 69.201                 & 4,68\%     \\
atlas2b1.intec.ugent.be & 3.247                 & 69.418                 & 4,68\%     \\
atlas2b2.intec.ugent.be & 3.238                 & 69.449                 & 4,66\%     \\
atlas3a1.intec.ugent.be & 3.256                 & 69.952                 & 4,65\%     \\
atlas3a2.intec.ugent.be & 3.251                 & 69.509                 & 4,68\%     \\
atlas3b1.intec.ugent.be & 3.247                 & 70.212                 & 4,62\%     \\ \bottomrule
\end{tabular}
\caption{Aantal interessante objecten t.o.v. totaal aantal objecten}
\label{tabel-fracties}
\end{table}

\subsubsection{Conclusie}

Gezien het lage percentage van gegevens die voor ons echt interessant is,
loont het zeker de moeite om een lijst op te stellen van de \glspl{oid} die interessant zijn.
Dit zal sowieso al schelen in de uitvoeringstijd omdat er 20 keer minder gegevens moeten opgevraagd worden,
bovendien scheelt dit ook in de opslag van de gegevens.
Zeker als er meerdere kopieën van dezelfde gegevens bijgehouden worden over een bepaalde tijdspanne.


\subsection{Bulkrequests}
\label{bulkrequests-benchmarks}

In \cref{snmp-operaties,latency} besproken we dat het samenbundelen van meerdere objecten in een request, althans theoretisch, een zeer goed idee is.
Alvorens we de code weggooien in de \nwmretriever{} die gebruik maakt van GETNEXT-requests om een SNMP walk te doen,
kunnen we beter eerst testen wat voor snelheidswinsten we mogen verwachten bij het gebruik van bulkrequests.
Daarna kunnen we beslissen of het de moeite waard is om deze manier van werken te implementeren.

Om dit te testen maken we gebruik van reeds bestaande implementaties:
de \textit{snmpwalk} en \mbox{\textit{snmpbulkwalk}} tools van Net-SNMP maken respectievelijk gebruik van GETNEXT- en
GETBULK-requests om een SNMP walk te doen van een gegeven \gls{oid}.
Uitleg en voorbeelden over hoe je de Net-SNMP tools kunt gebruiken vind je terug in \cref{manieren-om-snmp-gegevens-op-te-vragen}.
Herinner je dat we het aantal objecten per pakket kunnen bepalen door het aantal max-repetitions te wijzigen.
Standaard stond die op 10.

\subsubsection{Meetresultaten}

Om te beginnen bevragen we een virtuele machine vanaf een andere.
In principe kunnen we ook onszelf bevragen, maar dat is geen realistische situatie want dan is er helemaal geen netwerkvertraging.
De gemiddelde pingtijd tussen twee virtuele machines is 0,468 ms.
We doen achtereenvolgens een SNMP walk van de ganse SNMP-agent (goed voor ongeveer 4200 objecten),
gevolgd door meerdere SNMP walk's met bulk-requests met een verschillende aantal objecten per request.
Elke test herhalen we 100 keer en van elke test houden we het aantal ontvangen objecten bij alsook de tijd die hiervoor nodig was.
Omdat het aantal objecten variabel is, sommeren we op het einde alle objecten en alle tijden.
Uiteindelijk bekomen we twee metrieken: als we het totaal aantal objecten delen door de totale uitvoeringstijd,
dan bekomen we het gemiddeld aantal objecten per tijdseenheid (hier ms).
Het inverse daarvan is de gemiddelde tijd die nodig is om een object op te vragen.
Wij zullen gebruik maken van de eerste metriek die wat intuïtiever is.

\begin{table}[h]
\centering
\begin{tabular}{@{}lrrr@{}}
\toprule
Operatie (objecten per request) & Objecten/ms & Objecten/ms\textsuperscript{*} & Uitschieters \\ \midrule
SNMP Walk                       & 1,843       & 1,843           & 0            \\
SNMP Bulkwalk (10)              & 6,937       & 6,937           & 0            \\
SNMP Bulkwalk (50)              & 8,752       & 9,655           & 5            \\
SNMP Bulkwalk (100)             & 8,054       & 9,892           & 10           \\
SNMP Bulkwalk (200)             & 7,590       & 9,845           & 14           \\
SNMP Bulkwalk (500)             & 7,854       & 9,887           & 13           \\
SNMP Bulkwalk (1000)            & 7,225       & 9,857           & 19           \\ \midrule[.5pt]
\multicolumn{4}{l}{\textsuperscript{*} \footnotesize{Zonder uitschieters}}
\end{tabular}
\caption{Gemiddeld aantal objecten per ms voor SNMP walk en SNMP bulkwalk}
\label{tabel-bulkrequests}
\end{table}

De resultaten zie je in \cref{tabel-bulkrequests}.
De eerste kolom bevat de operatie met tussen haken het aantal objecten per request indien het om een SNMP bulkwalk gaat.
De tweede kolom bevat het \emph{gemiddeld} aantal objecten per ms.
De derde kolom bevat weer het gemiddeld aantal objecten per ms, maar zonder uitschieters.
De laatste kolom ten slotte bevat het aantal uitschieters.

Bij de resultaten van SNMP bulkwalk's met een groot aantal objecten per request zagen we soms een klein aantal uitschieters (telkens op 100 iteraties).
Hier spreken we van een uitschieter als hij er anderhalf zo lang keer over doet als de meeste anderen.
Bijvoorbeeld bij de SNMP bulkwalk's met 1000 objecten per request deden de meeste er ongeveer 0,44 ms over.
Een klein aantal deed er echter 1,5 of zelfs 2 ms over.
Omdat de andere tijdsmetingen zeer dicht bij elkaar liggen (minder dan 0,10 ms afwijking) vermoeden we
dat de virtuele machine tijdelijk minder rekenkracht toegewezen krijgt door het gastheerbesturingssysteem.
Wellicht zien we dit verschijnsel vooral bij hoge aantallen objecten per request omdat die meer rekenwerk vereisen.
Latere tests waarbij de SNMP-agent geen virtuele machine is vertonen dit gedrag niet.

Uit de resultaten kunnen we alvast afleiden dat het samenbundelen van meerdere objecten per request zeer grote snelheidswinsten oplevert,
zelfs al voor 10 objecten per request.
Daar zien we dat het al 3,76 keer zo snel gaat als een gewone SNMP walk.
Bij de andere gaat het 3,92 (1000 objecten/request) tot 4,75 (50 objecten/request) keer zo snel als we de resultaten met uitschieters bekijken.
Houden we geen rekening met de uitschieters dan loopt het snelheidsverschil weinig uiteen en zien we
dat het gemiddeld 5,33 keer zo snel gaat voor 50 tot 1000 objecten per request.

We zien dat het weinig zin heeft om meer dan 100 objecten per request te bundelen.
Om beter het ideaal aantal objecten per request te schatten testen we het bereik tussen 10 en 100 objecten per request en voegen we er telkens 10 objecten bij.
De resultaten daarvan zie je in \cref{tabel-bulkrequests-bulksizes}.

\begin{table}[h]
\centering
\begin{tabular}{@{}lrrr@{}}
\toprule
Operatie (objecten per request) & Objecten/ms & Objecten/ms\textsuperscript{*} & Uitschieters \\ \midrule
SNMP Bulkwalk (10)              & 6,856       & 6,856         & 1            \\
SNMP Bulkwalk (20)              & 8,455       & 8,455         & 0            \\
SNMP Bulkwalk (30)              & 8,873       & 8,873         & 0            \\
SNMP Bulkwalk (40)              & 8,943       & 8,943         & 0            \\
SNMP Bulkwalk (50)              & 8,672       & 8,913         & 2            \\
SNMP Bulkwalk (60)              & 8,709       & 9,108         & 2            \\
SNMP Bulkwalk (70)              & 8,514       & 9,519         & 6            \\
SNMP Bulkwalk (80)              & 9,103       & 9,560         & 3            \\
SNMP Bulkwalk (90)              & 8,945       & 9,627         & 3            \\
SNMP Bulkwalk (100)             & 8,336       & 9,725         & 9            \\ \midrule[.5pt]
\multicolumn{4}{l}{\textsuperscript{*} \footnotesize{Zonder uitschieters}}
\end{tabular}
\caption{Gemiddeld aantal objecten per ms voor SNMP bulkwalk met 10-100 objecten per request}
\label{tabel-bulkrequests-bulksizes}
\end{table}

Opnieuw zien we een klein aantal uitschieters (opnieuw op 100 iteraties).
Verder zien we dat het gemiddeld aantal objecten per ms, althans als we de uitschieters buiten beschouwing laten, stelselmatig toeneemt.
Houden we wel rekening met de uitschieters, dan zien we een piek bij 80 objecten per request.

Alvorens we onze conclusies trekken, herhalen we de test nogmaals maar op een productieswitch van iMinds.
De gemiddelde pingtijd naar deze switch bedraagt 1,831 ms.
Omdat we hier problemen ondervonden bij het opvragen van grote aantallen gegevens (zie \cref{probleem-dos-bescherming}),
hebben we ons beperkt tot het overlopen van de interfacetabel, goed voor ongeveer 2750 objecten.
De resultaten van deze test zie je in \cref{tabel-bulkrequests-switch}.

\begin{table}[h]
\centering
\begin{tabular}{@{}lrrr@{}}
\toprule
Operatie (objecten per request) & Objecten/ms & Snelheid t.o.v. walk & \begin{tabular}[c]{@{}r@{}}Snelheidsverschil\\ t.o.v. vorige operatie\end{tabular} \\ \midrule
SNMP Walk                      & 0,448       & 100,00\%             &                                                                                 \\
SNMP Bulkwalk (10)             & 1,484       & 331,51\%             & 231,51\%                                                                        \\
SNMP Bulkwalk (20)             & 1,745       & 389,88\%             & 17,61\%                                                                         \\
SNMP Bulkwalk (40)             & 1,833       & 409,56\%             & 5,05\%                                                                          \\
SNMP Bulkwalk (50)             & 1,848       & 412,86\%             & 0,81\%                                                                          \\
SNMP Bulkwalk (100)            & 1,843       & 411,67\%             & -0,29\%                                                                         \\
SNMP Bulkwalk (200)            & 1,867       & 417,04\%             & 1,30\%                                                                          \\
SNMP Bulkwalk (500)            & 1,846       & 412,39\%             & -1,11\%                                                                         \\
SNMP Bulkwalk (1000)           & 1,876       & 419,03\%             & 1,61\%                                                                          \\ \bottomrule
\end{tabular}
\caption{Gemiddeld aantal objecten per ms voor SNMP walk en SNMP bulkwalk op een productieswitch}
\label{tabel-bulkrequests-switch}
\end{table}

De test werd uitgevoerd vanaf dezelfde virtuele machine, maar er waren deze keer geen uitschieters in de resultaten.
Hier zien we dat het nog steeds sterk de moeite loont om over te stappen op bulk-requests.
Alhoewel het hier geen vijf keer sneller gaat zoals bij de vorige test, met ruim vier keer sneller zijn we ook al tevreden.
De grootste winst zit bij 10 objecten per request, maar er worden nog kleine winsten geboekt bij verdere verhoging.
Vanaf 50 objecten per request begint de winst af te vlakken.

\subsubsection{Conclusie}

De testen met GETBULK-requests zien er veelbelovend uit, met SNMP walk's die tot vier keer sneller gaan dan hun variant met GETNEXT-requests.
Het is overduidelijk dat het dan ook sterk de moeite loont om SNMP walk's te implementeren met behulp van GETBULK-requests.

Voor wat betreft het ideaal aantal objecten dat we per request opvragen valt er te discussiëren.
Gezien de resultaten bij de productieswitch uitwijzen dat de snelheidswinsten afvlakken vanaf 50 objecten per request lijkt ons dat een goed aantal
om te gebruiken bij de implementatie voor \nwmretriever.
Alhoewel Net-SNMP een veilige 10 objecten per request aanhoudt,
vinden we het toch de moeite om dit verder te verhogen gezien het toch nog een 25-tal procent sneller kan gaan ten opzichte van GETNEXT-requests.

Als we kijken naar het aantal op te vragen gegevens, de zien we dat de interfacetabel van een van de kleinere productieswitches alleen al bijna 3000 objecten bevat.
In \cref{fracties} zagen we dat het aantal interessante objecten bij een switch 3 à 5000 bedraagt, tot zelfs ruim 11000 voor een grotere switch.
Daarom neigen we des te meer naar hogere aantallen objecten per request voor als het over netwerkapparatuur gaat.

Natuurlijk kunnen we het aantal objecten per request laten aanpassen door de eindgebruiker,
maar met hetgeen we hierboven hebben geschreven voelen we ons zelfzeker dat 50 objecten per request een goede standaardwaarde is.


\todo[inline]{Nut van bulkrequest? Omzeilen van latency en overhead van pakketten...
Vooral het effect van latency op bulkrequests hadden we moeten testen.}


\subsection{SNMP Data Retriever versus Net-SNMP tools}

\todo[inline]{\nwmretriever{} Gebruikt het .NET platform, Net-SNMP op C.}

Bij deze test vergelijken we de performantie tussen de \nwmretriever{} en de Net-SNMP tools.
Alvorens we beginnen moeten we opmerken dat het niet echt een eerlijke vergelijking is,
want de geschiedenis van Net-SNMP dateert al terug van 1992\cite{net-snmp-history}.
\nwmretriever{} is in vergelijking nog een jong project dat nog volop ontwikkeld wordt.
Gedurende de verscheidene testen die we gedaan hebben genoot de software nog van meerdere updates.
Om een vast referentiepunt aan te houden werd echter geen rekening gehouden met deze updates.
Wel zullen we de updates vermelden als die relevant zijn voor een bepaalde test.

Behalve het verschil in maturiteit van de software doet de \nwmretriever{} nog iets meer dan de Net-SNMP tools.
De Net-SNMP tools ondersteunen maar een opdracht (een GET-request of een SNMP walk bijvoorbeeld) en voor slechts een toestel.
Om meerdere gegevens van verschillende toestellen op te vragen moet je de verschillende tools meerdere malen laten uitvoeren.
De resultaten worden uiteindelijk simpelweg uitgeschreven op het scherm.

Bij de \nwmretriever{} daarentegen wordt er gewerkt met een XML-bestand (zie \cref{snmp-data-retriever}) waarin je alle verschillende toestellen kunt opsommen,
en voor elk soort toestel kun je een lijst van opdrachten opstellen die moeten uitgevoerd worden voor dat type toestel.
Op het einde som je dan alle toestellen op en geef je mee om wat voor soort toestel het gaat zodat de software weet welke opdrachten moeten uitgevoerd worden.
Wanneer het programma wordt uitgevoerd worden alle nodige opdrachten voor alle opgegeven toestellen in parallel uitgevoerd.
Bij deze test houden we het wel maar bij een toestel, waardoor dat voordeel wegvalt in dit geval.
Na het ophalen van de gegevens worden de resultaten uiteindelijk weggeschreven in een databank (of een XML-bestand in een latere versie).
Die gegevens worden dan later verwerkt door andere tools van NetworkMining voor verschillende doeleinden zoals bijvoorbeeld het visualiseren van inventarissen.

\subsubsection{Meetresultaten}

Hier gaat het zoals gezegd slechts over het bevragen van een enkel toestel, namelijk een van de virtuele machines.
De bevragingen zelf gebeuren ook vanaf virtuele machines: de Net-SNMP tools worden zoals voorheen uitgevoerd op een andere Debian virtuele machine,
de \nwmretriever opnieuw op de voorziene Windows XP virtuele machine.
De Windows XP virtuele machine heeft iets meer geheugen (512 MB tegenover 256 MB bij Debian) omwille van
de grafische schil van Windows en de databank die er ook op draait,
maar heeft verder geen invloed op de test want de software zelf gebruikt een stuk minder dan 100 MB geheugen).

Omdat de \nwmretriever{} de \textit{endOfMibView}-exceptie niet ondersteunt (zie \cref{probleem-endofmibview-exceptie}),
is het niet mogelijk om een SNMP walk te doen van een ganse SNMP-agent.
Deze exceptie wordt opgegooid wanneer het einde van een \gls{mib}-bestand bereikt wordt en er dus geen verdere gegevens meer zijn.
De exceptie is een speciaal geval omdat ze geen gebruik maakt van het error-veld in het antwoordbericht.
Het error-veld staat dus onterecht op 0, wat aangeeft dat er zich geen fout heeft voorgedaan.
Daarom, en omdat het ongewoon is om een ganse SNMP-agent te overlopen, is het begrijpelijk dat de \nwmretriever nog geen ondersteuning had voor deze exceptie.
We hebben dit wel doorgegeven aan NetworkMining dus dat zal zeker opgelost zijn in een latere versie.

Omdat we dus geen ganse SNMP-agent kunnen overlopen kiezen we een \gls{oid} die voldoende gegevens bevat.
We gaan uiteindelijk voor de \textit{mgmt}-tak (1.3.6.1.2), de ouder van de \textit{mib-2}-tak.
Die \gls{oid} is goed voor ongeveer 1700 objecten.

Bij de Net-SNMP tools hebben we het gemiddelde genomen van 50 iteraties,
bij de \nwmretriever{} gaat het om 10 iteraties omdat die testen nog niet geautomatiseerd waren.
De resultaten zie je in \cref{tabel-nwmretriever-vs-net-snmp}.

\begin{table}[h]
\centering
\begin{tabular}{@{}lrr@{}}
\toprule
Operatie (objecter per request) & Uitvoeringstijd (ms) & Objecten/ms \\ \midrule
SNMP Data Retriever             & 4575                 & 0,357       \\
Net-SNMP Walk                   & 606                  & 2,928       \\
Net-SNMP Bulkwalk (10)          & 145                  & 12,218      \\
Net-SNMP Bulkwalk (50)          & 100                  & 17,740      \\ \bottomrule
\end{tabular}
\caption{Metingen tussen de \nwmretriever{} en de Net-SNMP tools}
\label{tabel-nwmretriever-vs-net-snmp}
\end{table}

Opnieuw zie je in de eerste kolom over welke operatie het gaat alsook hoeveel objecten per request opgevraagd werden.
In de tweede kolom staat de gemiddelde uitvoeringstijd en in de laatste het gemiddeld aantal objecten er werden opgehaald per ms.
De tool die we gebruiken om de uitvoeringstijd te meten, GNU time, heeft een precisie van 10 ms.

Eerst en vooral zien we dat er een groot verschil is tussen de resultaten van de \nwmretriever{}
en de Net-SNMP walkopdracht, en zoals voorheen tussen de Net-SNMP walk- en bulkwalkopdracht.
Dit geeft aan dat er wellicht nog veel te optimaliseren valt, maar het resultaat valt ook deels te verklaren door de bijkomende databankinteracties.

We zien ook dat het samenbundelen van 50 objecten per request inderdaad nog een stuk beter is dan slechts 10 objecten.
Het is je misschien ook opgevallen dat de resultaten nog een stuk beter zijn hier dan bij de tests over bulkrequests (\cref{bulkrequests-benchmarks}).
Nochthans is het enige verschil met die test de datum waarop de test werd uitgevoerd en het aantal objecten dat werd opgehaald.
Bij die test overliepen we echter gans de SNMP-agent en kregen we op het einde dan ook een endOfMibView-exceptie,
mogelijks heeft dat een impact gehad op de resultaten.
Ter vergelijking, de meeste bulkwalks hadden 440 ms nodig voor ong. 4200 objecten tegenover de 100 ms voor de ong. 1700 objecten bij deze test.

We hadden graag ook de test herhaald op een productieswitch,
maar we stootten hierbij opnieuw op problemen bij het genereren van veel verkeer op het netwerk van iMinds (zie \cref{probleem-dos-bescherming}).

\todo[inline]{We zouden hier kunnen de test herhalen met een Wireshark capture om te zien of er een afwijking is in de tijd nodig per request...}

\subsubsection{Conclusie}

Er is nog flink wat ruimte over voor verbetering bij de \nwmretriever{} als we de uitvoeringstijden vergelijken met die van de Net-SNMP tools.
Wat voor performantiewinsten en in welke componenten we die kunnen boeken zal blijken uit de profileranalyse in \cref{profiling}.
Ook het verhogen van het aantal objecten per request van 10 naar 50 heeft een positieve invloed op de uitvoeringstijd.

\subsection{Profiling van de SNMP Data Retriever}
\label{profiling}

In deze paragraaf gaan we de SNMP Data Retriever van NetworkMining onder de loep nemen met de ingebouwde profiler van Visual Studio.
Een profiler zal ons enkele belangrijke inzichten verschaffen over wat er achter de schermen gebeurt bij het uitvoeren van de retriever.
Specifiek:

\begin{itemize}
	\item Hoe lang bepaalde stukken code er over doen
	\item Hoe vaak bepaalde stukken code uitgevoerd worden (zogenaamde hot code/paths)
	\item Problematische stukken code detecteren die er veel langer over doet dan we verwachten
	\item En bijgevolg welke stukken het meeste potentieel bieden om te optimaliseren
\end{itemize}

Daar waar we problemen vinden of kansen zien om te optimaliseren zullen we de nodige aanpassingen doen en de resultaten daarvan testen.
Een van de aanpassingen die we bekijken is het gebruik van GETBULK-requests, zoals we onderzocht hebben in \cref{bulkrequests-benchmarks}.
Maar om te beginnen leggen we het gebruik van de profiler uit in Visual Studio 2013.

\subsubsection{Gebruik van de profiler in Visual Studio 2013}

De profiler in Visual Studio 2013 is erg makkelijk te gebruiken.
Om te beginnen open je je project en klik je op \emph{Analyze} in de werkbalk en kies je voor \emph{Performance and Diagnostics}.
Als alternatief kun je ook van de ALT+F2 sneltoets gebruik maken. %TODO: Koppelteken
Als \emph{Target} staat standaard het huidige project geselecteerd.
Onder \emph{Available Tools} zou normaal ook de \emph{Performance Wizard} moeten geselecteerd zijn.
Zoals de beschrijving al verklapt houdt dit onder andere het meten van CPU- en RAM-gebruik in.
\Cref{performance-wizard} toont de \emph{Performance Wizard} die je te zien krijgt als je op \emph{Start} klikt.
Hier moet je kiezen van welke profilingmethode je wenst gebruik te maken.
Wij kiezen voor de eerste: \emph{CPU Sampling}.
De rest van de stappen staan standaard goed dus mag je meteen op \emph{Finish} klikken.

\begin{figure}[]
	\centering
	\includegraphics[scale=0.50]{figures/profiler/performance-wizard}
	\caption{De Performance Wizard}
	\label{performance-wizard}
\end{figure}

Wanner het programma klaar is met uitvoeren worden de resultaten geanalyseerd.
Als dat klaar is krijg je een algemeen overzicht van de resultaten.
Eerst en vooral zie je een grafiek met het CPU-gebruik doorheen de uitvoeringstijd van de applicatie.
Daaronder zie je de \emph{Hot Paths}, dat zijn de functies die verantwoordelijk zijn voor het grootste deel van de uitvoeringstijd.
Waar wij in geïnteresseerd zijn is hieraan gerelateerd: de \emph{Call Tree View}.
Die geeft je een boomstructuur van functies die elkaar oproepen en enkele belangrijke statistieken:
hoeveel keer een functie werd opgeroepen en hoeveel tijd de functie gemiddeld nodig had om uit te voeren,
dit zowel procentueel (ten opzichte van de totale uitvoeringstijd) als in absolute tijd.

De call tree van de SNMP Data Retriever kun je zien in \cref{call-tree}.
Hierbij werd de \emph{Main} functie opengeklapt. %TODO: Koppelteken
Je kunt functies verder open klappen om te zien welke andere functies worden opgeroepen en hun aandeel in de uitvoeringstijd analyseren.
Dit kan verder gaan tot je atomaire functies krijgt die geen andere functies meer oproepen.

In de call tree zie je naast de functienaam een aantal verschillende kolommen. Hieronder volgt de lijst van de kolommen en hun betekenis.

\begin{itemize}
	\item \textbf{Number of calls:}
		dit spreekt vrij voor zichzelf. Dit is het aantal keren dat een functie opgeroepen werd.
	\item \textbf{Elapsed Inclusive Time \%:}
		dit is het percentage van de uitvoeringstijd dat werd gespendeerd in deze functie en zijn kinderen.
	\item \textbf{Elapsed Exclusive Time \%:}
		dit is het percentage van de uitvoeringstijd dat uitsluitend in deze functie werd gespendeerd, dus \emph{exclusief} zijn kinderen.
	\item \textbf{Avg Elapsed Inclusive Time:}
		dit is de gemiddelde uitvoeringstijd in milliseconden van deze functie en zijn kinderen.
	\item \textbf{Avg Elapsed Exclusive Time:}
		dit is de gemiddelde uitvoeringstijd in milliseconden van uitsluitend deze functie, dus weer \emph{exclusief} zijn kinderen.
		\todo{Check of er geen pagebreak is op de individuele items.}
\end{itemize}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{figures/profiler/call-tree}
	\caption[De Call Tree]{De Call Tree. De kolommen van links naar rechts:
		\emph{Function Name},
		\emph{Elapsed Inclusive Time \%},
		\emph{Elapsed Exclusive Time \%},
		\emph{Avg Elapsed Inclusive Time},
		\emph{Avg Elapsed Exclusive Time}.}
	\label{call-tree}
\end{figure}

\subsubsection{Meetresultaten}

Voor het wegschrijven van de resultaten van de SNMP Data Retriever installeren we een lokale databank.
\todo{Vertellen we waarom?}
De retriever verwacht een MySQL databank, maar wij kiezen voor een MariaDB-installatie.
Omdat MariaDB een drop-in vervanging is voor MySQL is dat echter geen probleem.
Op het moment van installatie was de laatste stabiele versie 5.5.33a.

We doen een walk van de volgende twee \glspl{oid} op een enkele productieswitch: ip (1.3.6.1.2.1.4) en dot1dBase (1.3.6.1.2.1.17.1).
Dit zal ons 443 objecten opleveren, waarvan 441 die voor ons relevant zijn.
Volgens de profiler doet de retriever daar ongeveer 7,4 seconden over.
De call tree van de retriever hebben we voor de leesbaarheid in een tabel gegoten (zie \cref{call-tree-main}).
De functies met een extreem kleine uitvoeringstijd (minder dan 0,01\%) hebben we achterwege gelaten.
De kolommen die je ziet zijn de functie, het aantal oproepen, de \emph{inclusieve} tijd als percentage van de totale uitvoeringstijd en
de gemiddelde \emph{inclusieve} tijd in milliseconden.

% Loglevel 2
\begin{table}[h]
	\centering
	\begin{tabular}{@{}lrrr@{}}
		\toprule
		Functie                                                  & Calls & Tijd (\%) & Tijd (ms) \\ \midrule
		SNMPDataRetrieval.RetrieveFromDevice                     & 1     & 64,39     & 4.772,57  \\
		SNMPDataRetrieval.Initialize                             & 1     & 25,37     & 1.880,45  \\
		SNMPDataRetrieval.ReadDeviceTypes                        & 1     & 4,73      & 350,46    \\
		SNMPDataRetrieval.CreateDBTable                          & 1     & 2,60      & 192,76    \\
		SNMPDataRetrieval.ReadDevices                            & 1     & 0,78      & 57,86     \\
		Microsoft.VisualBasic.CompilerServices.NewLateBinding.L… & 1     & 0,28      & 21,11     \\
		ComFunSQLConnection.GetSQLSelectData                     & 1     & 0,24      & 17,95     \\
		ComFunSQLConnection.DoSQLNonQuery                        & 1     & 0,19      & 14,18     \\
		ComFunLogger.Close                                       & 1     & 0,12      & 8,54      \\
		ComFunLogger.Log                                         & 3     & 0,08      & 1,89      \\
		ComFunSQLConnection.TableExists                          & 3     & 0,03      & 0,84      \\ \bottomrule
	\end{tabular}
	\caption{De call tree van de Main methode} %TODO: Koppelteken
	\label{call-tree-main}
\end{table}

\subsubsection{RetrieveFromDevice-methode}

\todo[inline]{Titel: functienaam (RetrieveFromDevice) of oplossing/onderdeel/probleem (Bulk requests). \\
Hier maakt het weinig uit maar bij het volgende deel wel: Initialize of Logging (wat het probleem meteen weggeeft).}

We beginnen met de functie die het meeste tijd in beslag neemt: de \emph{RetrieveFromDevice} functie. %TODO: Koppelteken
Zoals de naam al verklapt gaat het hier om de methode die de requests stuurt om de gevraagde gegevens op te halen van de verschillende toestellen.

\todo[inline]{Hoort de uitleg over de werking van de SNMP Data Retriever hier?}
De manier waarop dit gebeurt is als volgt:
voor elk toestel dat ondervraagd moet worden wordt er een aparte thread gestart, met een maximum van 50 threads.
Elk van die threads zal alle gegevens opvragen die opgevraagd moeten worden voor dat toesteltype (zie de configuratie van de \nwmretriever, \cref{snmp-data-retriever-configuratie}).
Wanneer een thread klaar is met gegevens opvragen wordt de thread verwijderd.
Indien er nog toestellen zijn die nog moeten ondervraagd worden, zal er dan een nieuwe thread opgestart worden voor het volgende toestel. \todo{Volledige uitleg over thread management geven of later uitleggen bij verbeteringen? Dit zal aan bod komen bij grootschalige testen.}
Dit gaat zo door tot alle toestellen zijn ondervraagd.

In \cref{snmp-operaties} werden de verschillende SNMP operaties besproken waarmee men
gegevens kan opvragen. De originele versie van de SNMP Data Retriever die we eerst testen maakt gebruik van
GET-requests voor enkelvoudige gegevens en GETNEXT-requests om een SNMP walk te doen van 
een ganse deelboom.

De call tree van de RetrieveFromDevice functie zie je in \cref{call-tree-retrievefromdevice}. %TODO: Koppelteken
De twee belangrijkste methoden hier zijn de \emph{SyncRequest} en de \emph{InsertResultRow} methoden. %TODO: Koppelteken
SyncRequest maakt deel uit van de \emph{SnmpSource} bibliotheek. %TODO: Koppelteken
Dit is de third party bibliotheek waarvan gebruik gemaakt wordt om alle SNMP interacties af te handelen. %TODO: Koppelteken
De SyncRequest methode wordt gebruikt om synchroon een request te versturen.
Het feit dat de request synchroon gebeurt wil zeggen dat de code wacht op het antwoord alvorens verder te gaan.
We zien dat de methode 443 keer is opgeroepen dus dat wil zeggen dat er 443 requests verstuurd zijn geweest.
Gemiddeld deed een request er een kleine 10 milliseconden over, allen samen goed voor bijna 60\% (oftewel 4,28 seconden) van de totale uitvoeringstijd.

\begin{table}[h]
	\centering
	\begin{tabular}{@{}lrrr@{}}
		\toprule
		Functie                                                  & Calls & Tijd (\%) & Tijd (ms) \\ \midrule
		SnmpSource.SnmpSession.SyncRequest                       & 443   & 57,74     & 9,66      \\
		SNMPDataRetrieval.InsertResultRow                        & 441   & 3,75      & 0,63      \\
		SnmpSource.SnmpSession..ctor                             & 1     & 1,85      & 137,38    \\
		Microsoft.VisualBasic.CompilerServices.NewLateBinding.L… & 445   & 0,42      & 0,07      \\
		ComFunSQLConnection.TableContainsColumn                  & 2     & 0,12      & 4,43      \\
		ComFunLogger.Log                                         & 451   & 0,07      & 0,01      \\
		SnmpSource.SnmpPdu..ctor                                 & 1     & 0,05      & 3,84      \\
		Microsoft.VisualBasic.CompilerServices.Conversions.ToBo… & 2     & 0,04      & 1,59      \\
		Microsoft.VisualBasic.CompilerServices.NewLateBinding.L… & 6     & 0,04      & 0,52      \\
		SnmpSource.SnmpVariable.CreateSnmpVariable               & 443   & 0,02      & 0,00      \\ \bottomrule
	\end{tabular}
	\caption{De call tree van de RetrieveFromDevice methode} %TODO: Koppelteken
	\label{call-tree-retrievefromdevice}
\end{table}

Het versturen van de GETNEXT-requests en wachten op het antwoord voor de SNMP walkopdrachten is dus
verantwoordelijk voor meer dan de helft van de totale uitvoeringstijd.
Gezien de resultaten die we gezien hebben in \cref{bulkrequests-benchmarks} waarbij GETBULK-requests vier keer sneller gingen dan GETNEXT-requests,
was de keuze dan ook snel gemaakt om de SNMP walkopdracht te implementeren met behulp van GETBULK-requests.

Na het implementeren van de SNMP walkopdracht met behulp van GETBULK-requests doen we een test op basis van dezelfde twee \glspl{oid} als hierboven.
Zoals we in \cref{bulkrequests-benchmarks} beslist hebben, vragen we 50 objecten per request.
We laten de oude en nieuwe implementatie 100 maal lopen en vergelijken de resultaten in \cref{tabel-nwmretriever-met-bulkrequests}.

\begin{table}[h]
\centering
\begin{tabular}{@{}lrrr@{}}
\toprule
                                                                                                 & Objecten & Uitvoeringstijd (s) & Objecten/ms \\ \midrule
SNMP Walk met GETNEXT-requests                                                                   & 472      & 7.371               & 0.064       \\
SNMP Walk met GETBULK-requests (50)                                                              & 441      & 3.131               & 0.141       \\
\begin{tabular}[c]{@{}l@{}}RetrieveFromDevice methode met\\   GETNEXT-requests\end{tabular}      & 472      & 5.060               & 0.093       \\
\begin{tabular}[c]{@{}l@{}}RetrieveFromDevice methode met\\   GETBULK-requests (50)\end{tabular} & 441      & 0.722               & 0.611       \\ \bottomrule
\end{tabular}
\caption{SNMP Walk op basis van GETNEXT-requests versus GETBULK-requests in de \nwmretriever{}}
\label{tabel-nwmretriever-met-bulkrequests}
\end{table}

De eerste twee rijen geven de totale uitvoeringstijd weer van de \nwmretriever{},
de laatste twee tonen de uitvoeringstijd van de RetrieveFromDevice methode gemeten met de profiler.
Het verschil in het aantal objecten tussen de SNMP walk met GETNEXT- en GETBULK-requests valt te verklaren door het feit dat er gebruik gemaakt wordt van
respectievelijk SNMP versie 1 en 2c. Versie 1 ondersteunt geen objecten van het type Counter64, dus die kunnen niet opgehaald worden\cite{snmp-counters-faq}.

\todo[inline]{Dit klopt niet!!! De v1 geeft MEER resultaten dan v2c! Dus er is iets anders aan de hand bij deze test...}

We zien dat gemiddelde uitvoeringstijd met ruim vier seconden ingekort wordt, goed voor een ruime verdubbeling van de snelheid.
Als we met de profiler echter enkel en alleen kijken naar methode voor de retrieval zien we dat de methode net zever keer sneller is
geworden dankzij het gebruik van BULK-requests.

\todo[inline]{Vergelijken met de theoretische resultaten? (Adhv. testen met VirtualBox \& iMinds Switchen)}

\begin{table}[h]
\centering
\begin{tabular}{@{}lrrr@{}}
\toprule
Functie                                                  & Calls & Tijd (\%) & Tijd (ms) \\ \midrule
SnmpSource.SnmpSession.SyncRequest                       & 11    & 11,07     & 33,62     \\
SNMPDataRetrieval.InsertResultRow                        & 441   & 6,46      & 0,49      \\
Microsoft.VisualBasic.CompilerServices.NewLateBinding.L… & 1.768 & 1,79      & 0,03      \\
SnmpSource.SnmpSession..ctor                             & 1     & 0,58      & 19,50     \\
Microsoft.VisualBasic.CompilerServices.NewLateBinding.L… & 443   & 0,58      & 0,04      \\
SNMPDataRetrieval.GetRequestsForDevice                   & 1     & 0,34      & 11,22     \\
SnmpSource.SnmpPdu..ctor                                 & 1     & 0,11      & 3,72      \\
Microsoft.VisualBasic.CompilerServices.Conversions.ToBo… & 441   & 0,10      & 0,01      \\
ComFunLogger.Log                                         & 1     & 0,05      & 1,64      \\
System.Array.Exists                                      & 6     & 0,05      & 0,27      \\
SnmpSource.SnmpVariable.CreateSnmpVariable               & 11    & 0,04      & 0,13     
\end{tabular}
\caption{De call tree van de RetrieveFromDevice methode met GETBULK-requests}
\label{call-tree-retrievefromdevice-bulk}
\end{table}

In \cref{call-tree-retrievefromdevice-bulk} zie je hoe de call tree van de RetrieveFromDevice methode er nu uitziet.
In de nieuwe implementatie doen de SyncRequest oproepen er drie keer zo lang over,
maar er moeten maar 11 requests meer verstuurd worden in plaats van 443.
Twee derde van de uitvoeringstijd van de RetrieveFromDevice-methode wordt besteed aan het ophalen van de gegevens en een derde aan het wegschrijven ervan.
De requests zelf zijn nu nog maar voor 11\% i.p.v. 58\% verantwoordelijk van de totale uitvoeringstijd.

\begin{table}[h]
\centering
\begin{tabular}{@{}lrrr@{}}
\toprule
Functie                                                  & Calls & Tijd (\%) & Tijd (ms) \\ \midrule
SNMPDataRetrieval.Initialize                             & 1     & 55,57     & 1.857,07  \\
SNMPDataRetrieval.RetrieveFromDevice2                    & 1     & 21,62     & 722,49    \\
SNMPDataRetrieval.ReadDeviceTypes                        & 1     & 12,03     & 401,84    \\
SNMPDataRetrieval.CreateDBTable                          & 1     & 5,31      & 177,32    \\
SNMPDataRetrieval.ReadDevices                            & 1     & 1,39      & 46,56     \\
ComFunSQLConnection.DoSQLNonQuery                        & 1     & 0,79      & 26,49     \\
ComFunSQLConnection.GetSQLSelectData                     & 1     & 0,52      & 17,33     \\
Microsoft.VisualBasic.CompilerServices.NewLateBinding.L… & 1     & 0,47      & 15,71     \\
ComFunLogger.Close                                       & 1     & 0,22      & 7,40      \\
ComFunLogger.Log                                         & 3     & 0,20      & 2,23      \\
ComFunSQLConnection.TableExists                          & 3     & 0,06      & 0,72      \\ \bottomrule
\end{tabular}
\caption{De call tree van de Main methode met GETBULK-requests}
\label{call-tree-main-bulk}
\end{table}

De call tree van de Main methode met de nieuwe implementatie zien we in \cref{call-tree-main-bulk}.
Voor de nieuwe implementatie hebben we een aparte methode geschreven gebaseerd op de oude: RetrieveFromDevice2.
Deze heeft dezelfde functionaliteit als voorheen maar maakt dus gebruik van GETBULK-requests.
De methode die zowel de gegevens ophaalt als wegschrijft is nu nog verantwoordelijk voor minder dan 22\% i.p.v. ruim 64\% van de totale uitvoeringstijd
en is zoals eerder gezegd zeven keer sneller dan de vorige methode.

De InsertResultRow-methode in de RetrieveFromDevice-methode hebben we nog niet bekeken.
Die is verantwoordelijk voor het wegschrijven van een gegeven in de databank.
Omdat er dus 441 gegevens zijn die binnen de SNMP walk vallen, werd de methode dus 441 keer opgeroepen.

Telkens een gegeven per keer in de databank klinkt even inefficiënt als het ophalen van een gegeven per keer.
Ook het invoegen van gegevens in een databank kan in bulk gebeuren met behulp van een zogeheten \textit{bulk insert} in plaats van een gewone \textit{insert}.
Maar als we kijken naar de tijd die nodig is om alle gegevens in de databank weg te schrijven dan zien we dat
dit slechts iets meer dan 200 ms of 6,5\% van de totale uitvoeringstijd bedraagt.
We beslissen dan ook dat het niet de moeite is om dit te implementeren omdat er nog veel grotere winsten elders kunnen gehaald worden\footnote{
	Wat we echter over het hoofd hebben gezien is dat we de databank geïnstalleerd hebben op een SSD.
	Een databank heeft enorm veel baat bij het gebruik van een SSD en heeft weinig moeite om een groot aantal inserts bij te houden zoals onze test.
	Pas bij de grootschalige tests ontdekken we onze fout, en daar komen we er dan ook op terug.
}.


\subsubsection{Initialize-methode}

Als we de call tree van de Main-methode bekijken dan valt op dat naast de RetrieveFromDevice-methode,
die logischerwijs een belangrijke factor is in de uitvoeringstijd,
er nog een methode is die voor een groot stuk medeverantwoordelijk is voor de uitvoeringstijd: de \textit{Initialize}-methode.

In de originele implementatie was ze verantwoordelijk voor 25\% van de uitvoeringstijd, in de nieuwe is dit opgelopen tot bijna 56\%!
De Initialize-methode doet er bijna 2 seconden over, dus zijn we erg niewsgierig wat er juist in deze methode gebeurt dat zoveel tijd nodig zou hebben.
Dus beginnen we met het analyseren van de call tree van de functie, te zien in \cref{call-tree-initialize}.
Wat we zien zijn twee oproepen naar een \emph{Log} methode die er gemiddeld bijna een seconde over doet \emph{per oproep}! %TODO: Koppelteken

\begin{table}[h]
\centering
\begin{tabular}{@{}lrrr@{}}
\toprule
Functie                                                   & Calls & Tijd (\%) & Tijd (ms) \\ \midrule
ComFunLogger.Log                                          & 2     & 45,61     & 762,05    \\
ComFunSQLConnection..ctor                                 & 1     & 8,15      & 272,18    \\
ComFunLogger.set\_LogFile                                 & 1     & 0,42      & 14,17     \\
Microsoft.VisualBasic.CompilerServices.Conversions.ToIn…  & 2     & 0,32      & 5,41      \\
ComFunLogger.Log                                          & 4     & 0,29      & 2,44      \\
System.Configuration.ConfigurationManager.get\_AppSettin… & 12    & 0,22      & 0,61      \\
ComFunLogger.Log                                          & 3     & 0,13      & 1,46      \\
ComFunLogger.Log                                          & 2     & 0,10      & 1,73      \\
ComFun.NetworkMiningCopyRightStatement                    & 1     & 0,06      & 2,14      \\
ComFunLogger..ctor                                        & 1     & 0,03      & 1,07      \\ \bottomrule
\end{tabular}
\caption{De call tree van de Initialize methode} %TODO: Koppelteken
\label{call-tree-initialize}
\end{table}

De \emph{ComFunLogger} is een stuk code die gebruikt wordt om te loggen naar een tekstbestand.
De naam komt van het feit dat ze een gemeenschappelijk stuk code is die over meerdere projecten kan
gebruikt worden: \emph{common functions}, of \emph{ComFun} voor kort.
Maar een functie die loggegevens wegschrijft naar een bestand hoort niet zo lang te duren.
I/O-operaties zijn kostelijk, maar niet \emph{zo} kostelijk. %TODO: Koppelteken
Als we de functie helemaal openklappen in \cref{call-tree-performancecounter} vinden we de echte dader:
een constructor van \emph{System.Diagnostics.PerformanceCounter}.
Een performance counter wordt gebruikt voor het monitoren van systeemcomponenten zoals
processoren, geheugen en netwerk-I/O. Als je ze gebruikt in je applicatie kunnen ze je %TODO: Koppelteken
informatie geven over de performantie van je programma.\cite{performance-counters-intro}
De ComFunLogger gebruikt ze om het geheugengebruik te meten en weg te schrijven in de logbestanden.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{figures/profiler/call-tree-performancecounter}
	\caption{De call tree van de Log methode}
	\label{call-tree-performancecounter}
\end{figure}

\todo[inline]{Herlees mij.}

Als oplossing werd ervoor gekozen om een alternatieve \emph{logging framework} te gebruiken.
Dit lijkt een drastische maatregel (en dat is het ook), maar daar zijn goede redenen voor.
Er zijn een heleboel gratis en open-source logging frameworks die reeds hun nut en kunnen bewezen hebben.
Zij zijn \emph{tried and true} oplossingen voor een algemeen probleem. \todo{Het zijn...}
Het is dus ook in de beste interesse voor een bedrijf om hiervoor te kiezen. \todo{Correcte zin?}
Financiëel is het een goede oplossing want de software is al ontwikkeld en is bewezen dat ze werkt.
Dit spaart tijd en geld uit voor de ontwikkeling van een eigen oplossing.
De software is gratis in gebruik dus er zijn geen licentiekosten aan verbonden.
Er zijn ook geen of lage onderhoudskosten. De software wordt al ingezet in zeer diverse omgevingen dus is al zeer uitgebreid.
De kans dat de software een bepaalde functionaliteit mist is dus klein.
En als er iets moet toegevoegd worden beschik je ook over de broncode.

Ook vanuit technisch opzicht is het een goede keuze.
Zoals gezegd heeft de software al zijn nut bewezen in diverse omgevingen.
In het specifieke geval van de ComFunLogger biedt een \emph{third party} oplossing ook een heleboel
extra flexibiliteit en features. Zo kan je loggen naar meerdere outputs en zijn er meerdere mogelijke outputs beschikbaar.
Je kunt bijvoorbeeld loggen naar tekstbestanden, consolevensters, databanken, enzovoort.

De twee belangrijkste redenen echter zijn het feit dat ze ontwikkeld zijn om een zo klein mogelijke performantieimpact te hebben en
dat de implementatie zeer simpel is.
Zo was het veel sneller om een ander logging framework te gebruiken dan om bekend te raken met de bestaande loggingcode en die te optimaliseren.

De keuze is uiteindelijk gevallen op Apache log4net en is gebaseerd op waarschijnlijk het bekendste logging framework voor java: Apache log4j.
Bij de keuze werd rekening gehouden met de performantieimpact en de features van de verschillende logging frameworks.\footnote{
	Een vergelijking tussen de bekendste logging frameworks voor .NET vind je 
	terug in de bronnenlijst bij bron \cite{logging-frameworks-and-performance} en \cite{logging-frameworks}.
}

\todo[inline]{De meest belangrijke reden zou toch moeten het feit zijn dat
log4net ervoor geoptimaliseerd is om zo weinig mogelijk impact te hebben op de uitvoeringstijd.}

Net als bij het implementeren van GETBULK-requests laten we opnieuw de \nwmretriever{} dezelfde \glspl{oid} opvragen van een productieswitch.
We herhalen de test 100 keer en berekenen de gemiddelde uitvoeringstijd en vergelijken met de vorige resultaten
in \cref{tabel-nwmretriever-met-bulkrequests-en-log4net}.
Om een zicht te hebben op de overhead van de \nwmretriever{} bekijken we ook de performantie van enkel de RetrieveFromDevice-methode (ophalen en wegschrijven in databank) en alle SyncRequest-methoden samen (enkel het ophalen van de gegevens).
Ten slotte vergelijken we ook met de resultaten die we in het verleden behaalden met Net-SNMP bij het bevragen van dezelfde switch.
Toen ging het wel om meer gegevens.

\begin{table}[h]
\centering
\begin{tabular}{@{}lrrr@{}}
\toprule
                                                                                                 & Objecten & Uitvoeringstijd (s) & Objecten/ms \\ \midrule
SNMP Walk met GETNEXT-requests                                                                   & 472      & 7.371               & 0.064       \\
SNMP Walk met GETBULK-requests (50)                                                              & 441      & 3.131               & 0.141       \\
\begin{tabular}[c]{@{}l@{}}SNMP Walk met GETBULK-requests en\\   log4net (50)\end{tabular}       & 441      & 1.839               & 0.240       \\
\begin{tabular}[c]{@{}l@{}}RetrieveFromDevice-methode met\\   GETBULK-requests (50)\end{tabular} & 441      & 0.722               & 0.611       \\
\begin{tabular}[c]{@{}l@{}}SyncRequest-methode met GETBULK-requests\\   (50)\end{tabular}        & 441      & 0.387               & 1.138       \\
Net-SNMP Bulkwalk (50)                                                                           & 2750     & 1.488               & 1.848       \\ \bottomrule
\end{tabular}
\caption{Vergelijking van de verschillende implementaties van \nwmretriever{} en Net-SNMP}
\label{tabel-nwmretriever-met-bulkrequests-en-log4net}
\end{table}

Opnieuw zien we een grote verbetering: de uitvoeringstijd is nu 1,7 keer sneller ten opzichte van de vorige versie,
en vier keer sneller dan de originele versie!
Alhoewel we zeer grote performantiewinsten behaald hebben ten opzichte van de originel versie van de \nwmretriever{},
als we kijken naar enkel naar het ophalen van de gegevens door de SyncRequest-methode,
dan is dit nog steeds 38\% trager dan Net-SNMP.
Maar omdat deze methode onderdeel is van de third-party bibliotheek SnmpSource kunnen we daar verder meer aan verbeteren.

\begin{table}[h]
\centering
\begin{tabular}{@{}lrrr@{}}
\toprule
Functie                                                  & Calls & Tijd (\%) & Tijd (ms) \\ \midrule
SNMPDataRetrieval.RetrieveFromDevice2                    & 1     & 38,80     & 725,19    \\
SNMPDataRetrieval.ReadDeviceTypes                        & 1     & 17,20     & 321,51    \\
SNMPDataRetrieval.Initialize                             & 1     & 17,02     & 318,13    \\
log4net.Config.XmlConfigurator.Configure                 & 1     & 10,25     & 191,52    \\
SNMPDataRetrieval.CreateDBTable                          & 1     & 8,28      & 154,77    \\
SNMPDataRetrieval.ReadDevices                            & 1     & 2,50      & 46,77     \\
ComFunSQLConnection.GetSQLSelectData                     & 1     & 0,95      & 17,75     \\
Microsoft.VisualBasic.CompilerServices.NewLateBinding.L… & 1     & 0,87      & 16,26     \\
ComFunSQLConnection.DoSQLNonQuery                        & 1     & 0,75      & 14,02     \\
log4net.LogManager.GetLogger                             & 1     & 0,44      & 8,14      \\
ComFunSQLConnection.TableExists                          & 3     & 0,12      & 0,76      \\
log4net.ILog.Info                                        & 3     & 0,06      & 0,39      \\ \bottomrule
\end{tabular}
\caption{De call tree van de Main methode met GETBULK-requests en log4net}
\label{call-tree-main-bulk-en-log4net}
\end{table}

De call tree van de Main-methode van de nieuwste versie zie je in \cref{call-tree-main-bulk-en-log4net}.
De totale uitvoeringstijd wordt nu voornamelijk bepaald door de volgende onderdelen:

\begin{itemize}
	\item 38,80\% (725 ms): bevragen van het toestel en het wegschrijven van de gegevens in de databank.
	\item 17,20\% (322 ms): het inlezen van de toesteltypes uit het XML-configuratiebestand.
		Het gebruik van reguliere expressies heeft hier de meeste impact op.
	\item 17,02\% (318 ms): het initialiseren,
		de meeste tijd wordt hier besteed aan de constructie van een SQL Connection-object (250 ms).
	\item 10,25\% (192 ms): het inlezen van het log4net configuratiebestand.
	\item 8,28\% (155 ms): het aanmaken van de databanktabellen.
	\item 2,50\% (47 ms): het inlezen van de te bevragen toestellen uit het XML-configuratiebestand.
\end{itemize}

\subsubsection{Conclusie}

Het implementeren van de SNMP walkopdracht met behulp van GETBULK-requests en het vervangen van het logging framework
door log4net heeft ervoor gezorgd dat de \nwmretriever{} vier keer sneller werkt in vergelijking met de originele versie.
Alhoewel we het hier niet bekeken hebben, valt er nog te verbeteren bij het invoeren van de opgehaalde gegevens in de databank.
Daar kunnen gegevens best in bulk weggeschreven worden in plaats van gegeven per gegeven zoals nu.

\todo[inline, caption={}]{

\begin{itemize}
	\item Waarom zijn er twee instanties nodig van de PerformanceCounter?
	\item Onderzoek op het internet leert ons dat PerformanceCounters hele kostelijke objecten zijn om aan te maken. Bron/citaat?
	\item x Oplossing: alternatieve loggingframework. Maar waarom heb je hiervoor gekozen ipv de huidige aan te passen?
	\item x Performantieredenen: ik heb een tried \& true logging framework opgezocht met nadruk op een minimale performantieimpact.
	\item x Plus de implementatie is ook sneller. Dan moet ik niet mijzelf bekend maken met de oude loggingcode en heb ik maar het 
		nieuwe loggingframework te includeren en alle logcalls te vervangen, wat vrij snel gebeurd is.
	\item x Lagere onderhoudskosten
	\item x Geen licentiekosten
	\item x Als leuke bonus krijg je er ook een heleboel extra features bij zoals logging naar meerdere outputs en meer outputformaten. (extra flexibiliteit)
	\item x Denk aan textfile, XML file, DB file, consoleuitvoer, etc.
	\item Nadeel: hoe groot is de extra code/binary van dit loggingframework? Andere nadelen?
\end{itemize}

}

\subsection{Tabellen rij per rij opvragen i.p.v. kolom per kolom}
\label{rij-per-rij}
\todo[inline]{Betere/kortere titel?}

Zoals uitgelegd in \cref{snmp-tabellen} worden tabellen kolom per kolom overlopen met de SNMP walkopdracht.
Een meer natuurlijke manier van werken zou de tabel echter rij per rij opvragen.
En misschien valt die methode zelfs sneller uit.

Een gewone SNMP walk wordt geïmplementeerd met GETNEXT-requests (of GETBULK-requests die meerdere GETNEXT-requests doet bij de SNMP-agent)
en vraagt zo steeds de volgende \gls{oid} op.
Om een tabel rij per rij op te vragen moeten we beginnen bij de eerste rij en sequentieel de kolommen overlopen van die rij.
Daarna overlopen we de kolommen van de volgende rij enzovoort.
Maar het kan nog sneller, we kunnen meteen alle kolommen van de eerste rij opvragen, gevolgd door alle kolommen van de tweede rij enzovoort.
Om dat te doen kunnen we een GETNEXT-request sturen met de \glspl{oid} van alle kolommen.
Dan weten de index van de eerste rij en sturen we de volgende GETNEXT-request met met de \glspl{oid} van alle kolommen met de index van de eerste rij.
Dat geeft ons de tweede rij en zo gaan we verder tot we de ganse tabel hebben opgehaald.

Jammer genoeg is het niet voldoende om een snmpbulkwalk te doen met de \glspl{oid} van alle kolommen want
die doet simpelweg sequentieel een snmpbulkwalk van elke opgegeven \gls{oid}.
Dus moeten we het wiel heruitvinden en een snmpbulkwalk implementeren die wel alle \glspl{oid} in parallel overloopt en op het juiste moment stopt.

Daarvoor maken we gebruik van een GETBULK-request met de \glspl{oid} van alle kolommen om meteen meerdere rijen tegelijkertijd op te vragen.
Het aantal max-repetitions is dan gelijk aan het aantal rijen dat in een request wordt opgevraagd.
En het aantal objecten in een request is natuurlijk gelijk aan het product van het aantal max-repetitions en het aantal kolommen.

Om op het juiste moment te stoppen moeten we ofwel op voorhand het aantal rijen kennen, ofwel moeten we de geretourneerde \glspl{oid}
bekijken om te zien of ze nog steeds deel uitmaken van de tabel zoals een gewone SNMP walk doet.

De voorwaarde om dit alles echter te kunnen doen is dat we vooraf de \glspl{oid} van de kolommen van de tabel moeten kennen.
Om de snelheid te vergelijken tussen beiden manieren om een tabel te overlopen,
bepalen we het maximum aantal rijen dat we tegelijkertijd kunnen opvragen zodat het aantal objecten in een request onder 50 blijft.
Dan overlopen we de tabel met een gewone SNMP walk op basis van GETBULK-requests met hetzelfde aantal objecten in een request.

Een voorbeeld: de interfacetabel ifTabel heeft 22 kolommen, dus dan vragen we 2 rijen per request op (goed voor 44 objecten).
Bij de gewone snmpbulkwalk geven we dan als aantal max-repetitions 44 op zodat beide methoden 44 objecten per request opvragen.

\subsubsection{Meetresultaten}

Om te beginnen vragen we de dot1dBasePortTable (1.3.6.1.2.1.17.1.4) op van de productieswitches bij iMinds.
Vanwege de problemen bij het genererern van grote hoeveelheden verkeer (\cref{probleem-dos-bescherming}) konden we slechts een iteratie per keer uitvoeren.
We hebben de test wel meermaals herhaald om zeker te zijn dat er geen grote verschillen zijn in de metingen,
maar het is toch belangrijk om in het achterhoofd te houden dat de resultaten niet erg nauwkeurig zijn.

\todo[inline]{Aantal objecten/ms? Niet echt interessant vermits we zo weinig metingen hebben...}

\begin{table}[h]
\centering
\begin{tabular}{@{}lrrr@{}}
\toprule
Toestel  & Objecten & Uitvoeringstijd rij per rij (s) & Uitvoeringstijd kolom per kolom (s) \\ \midrule
atlas1a1 & 1315     & 1.09                            & 0.59                                \\
atlas2a1 & 615      & 0.36                            & 0.25                                \\
atlas2a2 & 250      & 0.37                            & 0.28                                \\
atlas3a1 & 250      & 0.32                            & 0.21                                \\ \bottomrule
\end{tabular}
\caption{Tabel rij per rij opvragen versus kolom per kolom}
\label{tabel-serieel-vs-parallel}
\end{table}

Het is belangrijk om in het achterhoofd te houden dat de resultaten niet erg nauwkeurig zijn.
Niettemin kunnen we wel al een algemene trend waarnemen in de resultaten in \cref{tabel-serieel-vs-parallel}:
de tabel kolom per kolom ophalen is gemiddeld ongeveer anderhalf keer sneller dan ze rij per rij op te halen.
Deze trend zien we ook bij de andere productieswitches.
Voor alle duidelijkheid: deze testen zijn gebaseerd op de Net-SNMP tools!

Naar aanleiding van de grootschalige testen hebben we al een kleine opstelling klaar die gelijkaardig is aan de virtuele machines qua softwareconfiguratie,
maar waarbij elke machine op een \textit{dedicated server}\footnote{
	Bij een dedicated server worden de resources van een machine volledig toegewijd tot een of meer taken,
	in tegenstelling tot een virtuele machine die slechts een deel van de resources van een toestel krijgt.
} draait.
Omdat deze servers in een apart netwerk zitten hebben we gelukkig geen problemen met het genereren van veel verkeer,
we kunnen zoveel verkeer versturen als de fysieke verbinding aankan.
Hier kunnen we dus dezelfde test doen maar kunnen we ze wel 100 keer herhalen en het gemiddelde berekenen voor een nauwkeuriger resultaat.

De ping tijd tussen de twee toestellen is gemiddeld 0,204 ms.
Bij deze test vragen we de interfacetabel ifTable (1.3.6.1.2.1.2.2) op.
De tabel heeft 22 kolommen en de server heeft zes interfaces, samen goed voor 154 objecten.
Omdat 154 objecten wat aan de lage kant is,
kunnen we een aantal VLAN's toewijzen aan interfaces om het aantal objecten te verhogen,
want VLAN's komen ook in de ifTabel terecht.

We voegen 100 VLAN's toe, goed voor 2200 extra objecten of 2354 in totaal.
Om een VLAN aan te maken gebruik je het volgend commando:

\begin{lstlisting}[caption={Aanmaken van een VLAN}, label=commando-vlan]
$ sudo ip link add link eth3 name eth3.100 type vlan id 100
\end{lstlisting}

In dit commando voegen we het VLAN met ID 100 toe aan interface \textit{eth3} en geven we die de naam \textit{eth3.100}.

\begin{table}[h]
\centering
\begin{tabular}{@{}lrrr@{}}
\toprule
                & Objecten & Uitvoeringstijd (ms) & Objecten/ms \\ \midrule
Rij per rij     & 154      & 109                  & 1.413       \\
Kolom per kolom & 154      & 30                   & 5.133       \\
Rij per rij     & 2354     & 1523                 & 1.546       \\
Kolom per kolom & 2354     & 80                   & 29.425      \\ \bottomrule
\end{tabular}
\caption{Tabel rij per rij opvragen versus kolom per kolom op dedicated hardware}
\label{tabel-serieel-vs-parallel-vwall}
\end{table}

In \cref{tabel-serieel-vs-parallel-vwall} zien we de resultaten.
Opnieuw is het sneller om een tabel kolom per kolom op te vragen in plaats van rij per rij.
Deze keer is het zelfs ruim drie keer sneller bij 154.
2354 objecten is ongeveer 15 keer meer objecten, en de tabel rij per rij overlopen doet er ook 15 keer langer over.
Bij het kolom per kolom overlopen echter is de uitvoeringstijd amper met factor drie toegenomen!
We hebben de test (van 100 iteraties) meermaals uitgevoerd om  te bevestigen dat de resultaten kloppen,
maar de metingen waren zeer consistent.

\todo[inline]{Onderzoek de Wireshark trace.}

Behalve het snelheidsverschil zijn er nog andere redenen om tabellen kolom per kolom te overlopen:

\begin{itemize}
	\item De implementatie bestaat al en is uitvoerig getest.
	\item Voorkennis van de tabel is vereist: er moet dus een goede integratie zijn van \gls{mib}-bestanden
		om op de kolommen van elke tabel te bepalen en om te weten welke \glspl{oid} overeenstemmen met een tabel.
	\item Als de tabel deel uitmaakt van een SNMP walk van een hoger gelegen \gls{oid},
		dan moet er tijdens de uitvoering van implementatie gewisseld worden bij de \gls{oid} van de tabel, wat extra complexiteit veroorzaakt.
	\item Er moet rekening gehouden worden met randsituaties, zoals het voorkomen van gaten in de tabel\cite{net-snmp-table-holes}.
		Bij het rij per rij overlopen kan een antwoordpakket dus gegevens bevatten van meer dan een rij.
	\item Het aantal objecten per request moet een veelvoud zijn van het aantal kolommen.
\end{itemize}

\subsubsection{Conclusie}

Het rij per rij overlopen van een tabel is niet alleen trager dan ze kolom per kolom te overlopen,
ze brengt ook een heleboel problemen mee voor de implementatie.
Indien je toch een tabel rij per rij wil \textit{lezen}, dan kan je beter gebruik maken van bijvoorbeeld de Net-SNMP \textit{snmptable} tool.
Deze overloopt een tabel kolom per kolom zoals gewoonlijk, maar beeldt ze correct rij per rij af en houdt ook rekening met speciale gevallen zoals gaten in de tabel.


\subsection{Impact van de fragmentatie van pakketten}
\todo{Titel: Snelheidsimpact?}

Een van de laatste kleinschalige experimenten die we uitvoeren is het onderzoeken van de impact van fragmentatie van pakketten.
Dit doet zich voor als we proberen teveel objecten in een request te steken waardoor ze groter wordt dan de \gls{mtu} en
bijgevolg moet opgesplitst worden in meerdere pakketten alvorens ze verstuurd kan worden.
Dit onderzoek wordt bemoeilijkt omdat de objecten en zelfs de headers van een SNMP-bericht geen vaste grootte hebben.

We trachten om de gemiddelde grootte te bepalen van objecten om een schatting te doen van het ideaal aantal objecten per request
zodat we zo veel mogelijk objecten per request kunnen opvragen maar er toch zo weinig mogelijk fragmentatie voorkomt.
Om de gemiddelde objectgrootte te bepalen moeten we een SNMP-bericht volledig ontleden en de grootte van alle headers bepalen.
Eenmaal we de gemiddelde objectgrootte kennen, berekenen we hoeveel objecten er in een niet-gefragmenteerd bericht passen.
Vervolgens meten we hoelang een gefragmenteerd bericht er over doet tegenover een niet-gefragmenteerd bericht,
hoeveel gefragmenteerde berichten er werkelijk zijn in een SNMP walk en vergelijken we de uitvoeringstijd met
een SNMP walk met een ''optimaal'' aantal objecten per request.

\todo[inline]{
Eerst en vooral bekijken we in welke mate fragmentatie zich voordoet bij het aanhouden van 50 objecten per request.
Daarna zullen we de gemiddelde grootte bepalen van objecten om een schatting te doen van het ideaal aantal objecten per request
zodat we zo veel mogelijk objecten per request kunnen opvragen maar en toch zo weinig mogelijk fragmentatie voorkomt.
Tenslotte bekijken we wat voor impact de fragmentatie van pakketten/beide aanpakken hebben op de uitvoeringstijd en vormen we onze conclusie.
}

\subsubsection{Gemiddelde objectgrootte en optimaal aantal objecten per request}

Om de gemiddelde objectgrootte te berekenen doen we een SNMP walk van de mib-2-tak (1.3.6.1.2.1).
We gebruiken de variant op basis van GETNEXT-requests zodat elk antwoordbericht juist een object bevat.
Dat levert ons 3560 \emph{antwoord}berichten op.
De gemiddelde lengte van een antwoordbericht bedraagt 102,26 bytes.
Dus nemen we er willekeurig een antwoordbericht uit van 102 bytes om te ontleden.

Om te beginnen hebben we de ethernetheader, goed voor 14 bytes\cite{ethernet-header}.
Gevolgd door de ethernetheader is de IP-header van typisch 20 bytes\cite{ipv4-header-wiki}.
Na de IP-header komt de SNMP-\gls{pdu} die de overige 68 bytes ($ 102 - 14 - 20$) voor zijn rekening neemt.

De berichtstructuur van een SNMP-bericht hebben we besproken in \cref{snmp-berichtstructuur}.
Zoals gezegd hebben SNMP-berichten een variable headerlengte.
Maar veel headervelden hebben in de praktijk een vaste lengte.
We overlopen alle velden van een SNMP-header en bepalen hun typische lengte.
Als referentie kun je nogmaals de structuur van een SNMP-bericht bekijken in \cref{fig-berichtstructuur-4}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.40]{figures/snmp/berichtstructuur-3}
	\caption{Berichtstructuur van een SNMP-bericht in detail}
	\label{fig-berichtstructuur-4}
\end{figure}

\todo[inline]{Bronvermelding figuur.}

Het SNMP-bericht is een sequentie van:

\begin{itemize}
	\item De SNMP versie: steeds 1 byte.
	\item De community string: variabel, maar uitgaande van de community ''public'' gaat het om 6 bytes.
	\item De SNMP-\gls{pdu}: bestaande uit:
		\begin{itemize}
			\item De request ID: de unieke identificatie van een request.
				Bij de SNMP walk hadden alle requests de ID 1, dus: 1 byte.
			\item Het errorveld: een byte.
			\item Error Index: staat op nul indien er zich geen fout heeft voorgedaan, dus ook 1 byte.
			\item Varbind List: een sequentie van varbinds, maar bij de SNMP walk op basis van GETNEXT-requests gaat het om slechts een object.
				\begin{itemize}
					\item Varbind: stelt een object voor en is hetgeen we trachten te bepalen
						\begin{itemize}
							\item OID: variabel aantal bytes
							\item Value: variabel aantal bytes
						\end{itemize}
				\end{itemize}
		\end{itemize}
\end{itemize}

In totaal heeft een SNMP-bericht dus 8 vaste \gls{tlv}-tripletten (tot en met de Varbind List) met elk een overhead van 2 bytes voor de tag en length,
wat goed is voor 16 bytes.
De velden die een vaste lengte hebben zijn samen goed voor 10 bytes.
Elk object wordt voorgesteld door een Varbind bestaande uit een \gls{oid} en een value, samen goed voor een overhead van 6 bytes per object.
Uiteindelijk komen we uit op een headerlengte van het SNMP-bericht van 26 bytes, zonder objecten.

Als we de headerlengte van 26 bytes aftrekken van de 68 bytes van het SNMP-gedeelte van ons GETNEXT-response houden we nog 42 bytes over voor de varbind
die het object en zijn \gls{oid} en value bevatten.
Een gemiddeld object heeft dus een lengte van 42 bytes, inclusief zijn headers.

We gaan uit van een \gls{mtu} van 1500 bytes voor een ethernetpakket.
Als we daarvan de lengtes aftrekken van de ethernet-, IP- en SNMP-header houden we nog 1440 bytes ($1500 - 14 - 20 - 26$) over voor de objecten en hun headers.
Uitgaande van een gemiddelde objectlengte van 42 bytes is dat goed voor iets meer dan 34 objecten.

\subsubsection{Meetresultaten}

We laten de \nwmretriever{} op basis van de nieuwe implementatie een SNMP walk doen met 34 en 50 objecten.
Met behulp van Wireshark analyseren we de pakketten van beide tests.

We bepalen voor beide tests de impact van de fragmentatie op antwoordberichten door de gemiddelde tijd te meten die de pakketten nodig hebben.
De tijd die een pakket nodig heeft is dan het tijdsverschil tussen het versturen van de request tot het ontvangen van het responsebericht.
We bepalen tenslotte voor beide tests ook het percentage pakketten die gefragmenteerd werden.

\begin{table}[h]
\centering
\begin{tabular}{@{}lrrrrr@{}}
\toprule
                                                                           & Objecten/request & Aantal & Percentage & Tijd (ms) & Tijdsverschil (ms) \\ \midrule
\begin{tabular}[c]{@{}l@{}}Niet-gefragmenteerde\\   pakketten\end{tabular} & 50               & 22     &            & 6.996     &                    \\
\begin{tabular}[c]{@{}l@{}}Gefragmenteerd\\   pakketten\end{tabular}       & 50               & 50     & 69.44\%    & 9.822     & 2.826 (+40.39\%)   \\
\begin{tabular}[c]{@{}l@{}}Niet-gefragmenteerde\\   pakketten\end{tabular} & 34               & 83     &            & 5.843     &                    \\
\begin{tabular}[c]{@{}l@{}}Gefragmenteerd\\   pakketten\end{tabular}       & 34               & 22     & 20.95\%    & 7.882     & 2.039 (+34.9\%)    \\ \bottomrule
\end{tabular}
\caption{Impact en percentage van gefragmenteerde pakketten bij bulkrequests}
\label{tabel-fragmentatie-impact-percentage}
\end{table}

In \cref{tabel-fragmentatie-impact-percentage} zien we het aantal gefragmenteerde- en niet-gefragmenteerde pakketten bij bulkrequests van 34 en 50 objecten per request.
Ook getoond is de gemiddelde tijd die nodig was om een antwoordbericht te ontvangen en het tijdsverschil tussen de gefragmenteerde- en niet-gefragmenteerde pakketten.
We zien dat bij 50 objecten per request het percentage van pakketten dat gefragmenteerd werd vrij hoog ligt: net geen 70\% en dat ze er ook 40\% langer over doen.
Bij 34 objecten per request is dat percentage sterk gedaald en we zien ook dat de tijd die de pakketten erover doen gedaald is als gevolg van
het kleiner aantal objecten per request.

Maar de vraag is nu of het loont om 32\% minder objecten in een pakket te steken zodat ze 35 à 40\% sneller gaan?
Daarvoor laten we de \nwmretriever{} een SNMP walk doen van de \textit{enterprises}-tak (1.3.6.1.4.1) en de gekende mib-2-tak, samen goed voor 3558 objecten.
We herhalen de test 100 keer en berekenen de gemiddelde uitvoeringstijd.

\begin{table}[h]
\centering
\begin{tabular}{@{}rrrr@{}}
\toprule
Objecten/request & Objecten & Uitvoeringstijd (s) & Tijdsverschil (s) \\ \midrule
50               & 3558     & 17.735              &                   \\
34               & 3558     & 18.626              & 0.891 (+5.02\%)   \\ \bottomrule
\end{tabular}
\caption{Gemiddelde uitvoeringstijd van een SNMP walk met 50 en 34 objecten per request}
\label{tabel-fragmentatie-uitvoeringstijd}
\end{table}

In \cref{tabel-fragmentatie-uitvoeringstijd} zien we dat de SNMP walk met 34 objecten per request er gemiddeld bijna een seconde (of 5\%) langer over doet
dan de SNMP walk met 50 objecten per request.
Het is duidelijk dat de tijdswinst van niet-gefragmenteerde pakketten dus niet opweegt tegen de tijdswinst bij opvragen van meer objecten per request.

\subsubsection{Conclusie}

Ondanks het feit dat we antwoordberichten een stuk sneller krijgen als ze niet gefragmenteerd hoeven te worden,
lijkt die tijdswinst toch niet op te wegen tegen de tijdswinst van het opvragen van meer requests per object.
We kunnen dus beter meer requests per object opvragen, zelfs als dat een hoge mate van fragmentatie veroorzaakt.


\section{Grootschalige benchmarks en experimenten}

\todo[inline]{Inleiding. Kort uitleggen wat we allemaal doen in deze sectie.}

\subsection{Testopstelling}

\subsubsection{Virtual Wall}

De Virtual Wall is een testomgeving bij iMinds voor geavanceerde netwerken, gedistribueerde software en dienstenevaluatie.
Ze ondersteunt het onderzoek naar de schaalbaarheid van toepassingen.
De Virtual Wall bestaat uit een kleine 200 zware servers met processoren gaande van vier tot twaalf cores,
tot 24 GB geheugen en hebben tot zes gigabit netwerkinterfaces.
De servers zijn verbonden met grote switches die als schakelbord functioneren.
Zo kunnen de servers op afstand op elke mogelijke wijze met elkaar verbonden worden.
De servers zelf kunnen ook vanop afstand voorzien worden van voorgeconfigureerde software images.
Zo kunnen servers geconfigureerd worden als server, klant of zelfs een netwerkelement.
Op het netwerk kan men ook testen doen met verbindingen die pakketten verliezen, beperkte bandbreedte hebben of
een grote netwerkvertraging\cite{virtual-wall-uitleg, virtual-wall-specs}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{figures/virtual-wall}
	\caption{De Virtual Wall bij iMinds\cite{virtual-wall-specs}}
	\label{fig-virtual-wall}
\end{figure}

\subsubsection{Overzicht opstelling}
\todo[inline]{Titel ok?}

De bedoeling van de opstelling op de \vwall{}  is om een situatie na te bootsen waarbij een groot aantal toestellen ondervraagd moet worden.
Omdat de \vwall{} gedeeld wordt door meerdere onderzoekers kunnen we natuurlijk niet zomaar de helft van de servers gebruiken voor ons experiment.
Bovendien hebben we al gezien dat een virtuele machine met een core en 256 MB geheugen al meer dan voldoende is voor een SNMP-agent,
dan zou een machine met twaalf cores en 24 GB geheugen zware \textit{overkill} zijn.
Wat we dus doen is een groot aantal virtuele machines opzetten op een paar van die servers.
Er zijn verschillende virtualisatietechnologieën die we kunnen aanwenden waaronder OpenVZ en Xen.
Maar vanwege problemen die verder besproken worden in \cref{probleem-virtualisatie-vwall} werd er geopteerd voor \gls{lxc}.
Met \gls{lxc} kunnen we een 50-tal virtuele machines laten draaien op een enkele server.
We hebben dan uiteindelijk maar drie servers nodig: twee waarop de virtuele machines draaien en een waarop de \nwmretriever{} draait.
Elk van die 100 virtuele machines zal dan een eigen SNMP-agent draaien.

\subsubsection{Linux Containers}

\gls{lxc} is een lichte virtualisatietechnologie voor Linux die werkt op het niveau van het besturingssysteem.
Daarom gaat het niet om een volledige virtuele machine maar voorziet het een virtuele omgeving met een eigen procesruimte, bestandssysteem en netwerkinterfaces.
\gls{lxc} maakt hiervoor gebruik van de resourcemanagement- en resource-isolatiefeatures in de kernel zoals \textit{\gls{cgroups}}\footnote{
	\gls{cgroups} zorgen voor de resource-isolatie van de CPU, het geheugen, I/O, netwerk enzovoort\cite{lxc-wiki}.
} en \textit{namespace isolation}\footnote{
	Namespace isolation zorgt ervoor dat applicaties een volledig geïsoleerd zicht hebben op het besturingssysteem,
	waaronder processen, het netwerk, gebruikers en bestandssystemen\cite{lxc-wiki}.
}\cite{lxc-explained, lxc-wiki}.


\subsubsection{Netwerkconfiguratie}

De fysieke netwerktopologie is zeer eenvoudig: de drie servers worden simpelweg met elkaar verbonden via een switch.
De Linux containers (vanaf nu nodes genoemd) zijn daarmee echter nog niet bereikbaar.
Daarvoor moet er op elk van de twee hostmachines een bridge\footnote{
	Ondanks het feit dat deze functie in Linux een bridge genoemd wordt, komt de functionaliteit ervan overeen met een switch.
	De naam komt van het feit dat ze een brug vormt tussen twee of meer netwerkverbindingen.
} geconfigureerd worden met enerzijds zijn eigen netwerkinterface
en anderzijds alle nodes die op die machine draaien.
Daarvoor moet je voor elke node twee virtuele interfaces aanmaken die met elkaar verbonden zijn.
Een interface wijs je dan toe aan de bridge en de ander aan de node\cite{lxc-config}.
De commando's daarvoor zien er als volgt uit:

\begin{lstlisting}[caption={Linux containers verbinden met een bridge\cite{lxc-config}}]
# Bepaal de PID van de container vnode0:
$ pid=$(sudo lxc-info -pHn vnode0)

# Maak een paar virtuele interfaces aan die met elkaar verbonden zijn:
$ sudo ip link add name veth0 type veth peer name veth0_container

# Wijs een interface toe aan de bridge br0:
$ sudo brctl addif br0 veth0

# Wijs de andere interface toe aan de container:
$ sudo ip link set dev veth0_container netns $pid name veth0
\end{lstlisting}

Schematisch ziet de combinatie van de fysieke netwerkopstelling en de netwerkconfiguratie op de hosts er uit als in \cref{fig-vwall-opstelling}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{figures/virtual-wall-opstelling}
	\caption{Netwerkopstelling \vwall{}}
	\label{fig-vwall-opstelling}
\end{figure}

\todo[inline]{Pijlen aanpassen in de figuur.}


\subsubsection{Softwareconfiguratie containers}

Alle 100 nodes hebben een gelijkaardige softwareconfiguratie als van onze virtuele machines in VirtualBox van \cref{virtualbox}.
De nodes draaien elk hun eigen SNMP-agent en draaien het \gls{lldp}-protocol,
maar waar ze verschillen van de kleinschalige opstelling is dat ze niet als bridge geconfigureerd zijn.
Het belangrijkste is dat elke node over voldoende gegevens beschikt die we kunnen opvragen,
en met onze truc met het aanmaken van VLAN's (\cref{rij-per-rij}) kunnen we dat aantal makkelijk verhogen indien nodig.


\subsection{Impact databankinteracties}
\label{impact-db}

Als je de voetnoten gelezen hebt in onze tests met de profiler in \cref{profiling},
dan weet je dat we daar een fout hebben gemaakt waarbij we de databank geïnstalleerd hadden op een SSD.
Daardoor werd het probleem van het wegschrijven van de opgehaalde gegevens in de databank zwaar geminimaliseerd.
Omdat de \nwmretriever{} en de databank in de \vwall{}opstelling geïnstalleerd werden op een mechanische harde schijf,
merkten we dan ook snel op dat we bijlange niet dezelfde performantiewinsten behaalden als bij onze kleinschalige tests.
Ook NetworkMining ondervond performantieproblemen met de databank en hadden daarop een nieuwe versie ontwikkeld die als alternatief
de opgehaalde gegevens naar een XML-bestand kan wegschrijven.

Wegens tijdsgebrek hebben we het gebruik van bulk inserts niet meer kunnen implementeren.
Om toch de impact van het wegschrijven van de gegevens te kunnen meten hebben we wel vlug een optie ingebouwd
die het wegschrijven van de gegevens simpelweg achterwege laat.

\subsubsection{Meetresultaten}

We doen de test met 1, 10 en 100 nodes en dat zowel voor de originele versie als de nieuwe versie die gebruik maakt van bulkrequests en log4net als loggingframework.
Om de tabelgrootte te beperken vermelden we echter niet elke combinatie.
We doen opnieuw een SNMP walk van de mib-2- en enterprises-\glspl{oid}, nog steeds goed voor 3558 objecten.
We herhalen elke test 100 keer, behalve de tests waarbij een enkele iteratie extreem lang duurt (meer dan 1000 seconden, of ruim een kwartier).

\begin{table}[h]
\centering
\begin{tabular}{@{}ccrrrr@{}}
\toprule
\multicolumn{1}{l}{Nodes} & \multicolumn{1}{l}{Versie} & Insert & Uitvoeringstijd (s) & Factor & Factor nieuw vs oud \\ \midrule
\multirow{2}{*}{1}        & \multirow{2}{*}{Nieuw}     & Ja     & 6,634               &        &                     \\
                          &                            & Nee    & 2,669               & 2,49   &                     \\
\multirow{2}{*}{10}       & \multirow{2}{*}{Oud}       & Ja     & 77,333              &        &                     \\
                          &                            & Nee    & 29,762              & 2,60   &                     \\
\multirow{4}{*}{100}      & \multirow{2}{*}{Oud}       & Ja     & 1100,418            &        &                     \\
                          &                            & Nee    & 125,820             & 8,75   &                     \\
                          & \multirow{2}{*}{Nieuw}     & Ja     & 1051,373            &        & 1,05                \\
                          &                            & Nee    & 17,229              & 61,02  & 7,30                \\ \bottomrule
\end{tabular}
\caption{Impact van de databankinteracties}
\label{tabel-impact-db}
\end{table}

We zien de resultaten in \cref{tabel-impact-db}.
De eerste kolom duidt het aantal nodes aan, de tweede de versie waarbij oud de originele versie is en nieuw de versie die gebruik maakt van bulkrequests en log4net.
De derde kolom geeft aan of de resultaten worden weggeschreven in de databank of niet, de vierde de gemiddelde uitvoeringstijd en de vijfde geeft aan hoeveel keer
sneller de versie zonder inserts is.
De laatste kolom tenslotte geeft aan hoeveel keer sneller de nieuwe versie is tegenover de oude versie, met en zonder inserts.

De resultaten laten een duidelijk beeld zien:
er is een gigantisch verschil in uitvoeringstijd indien men wel of niet de gegevens wegschrijft in de databank.
Gaande van 2,5 keer bij een tot tien nodes, tot ruim 60 keer sneller bij de nieuwe versie!
Het is duidelijk dat het aanpakken van de inserts een zeer hoge prioriteit moet krijgen en dat het gebruik van bulk inserts sterk aangeraden is.

We zien ook dat het verschil tussen de oude versie en de nieuwe versie verwaarloosbaar is bij een groot aantal nodes als men de databankinserts niet aanpakt,
de nieuwe versie is daarbij slechts 5\% sneller.
Maar als de uitvoeringstijd niet tegengehouden wordt door de databaseinserts,
dan is de nieuwe versie ruim zeven keer sneller als er veel toestellen bevraagd moeten worden!
Het is dus belangrijk om de databankinteracties aan te pakken om de nieuwe versie van de \nwmretriever{} volledig tot zijn recht te laten komen.
\todo[inline]{Bij de kleinschalige tests zagen we al dat de nieuwe versie bij slechts een toestel al vier keer sneller was.
De snelheidswinst neemt dus sterk toe naarmate het aantal toestellen toeneemt dat bevraagd moet worden.}

\subsubsection{Conclusie}

Zowel bij kleine, maar vooral bij grote aantallen toestellen die bevraagd moet worden is er een grote impact op de uitvoeringstijd door de databankinteracties.
Het gebruik van bulk inserts moet dan ook een topprioriteit gemaakt worden.
Een mogelijke manier van werken zou zijn om het wegschrijven van gegevens in een aparte thread te laten verlopen.
Zo zijn er geen 50 threads die tegelijkertijd proberen hun data weg te schrijven in de databank.
Men kan een tabel in het geheugen bijhouden om initieel de resultaten in bij te houden om dan met die ene thread
de data uit de tabel met bulk inserts in zo groot mogelijke blokken weg te schrijven in de databank.

Omdat het implementeren en testen van die functionaliteit redelijk wat tijd in beslag kan nemen,
kan men overwegen om in afwachting de databank op te slaan op een SSD om zo het effect van de databankinteracties te minimaliseren.


\subsection{Benchmarks uitvoeringstijd}
\label{uitvoeringstijd-vwall}

In deze paragraaf beoordelen we de uitvoeringstijd van de nieuwe versie van de \nwmretriever{} ten opzichte van de oude.
Om de schaalbaarheid van de \nwmretriever{} te verbeteren hebben we al aanpassingen gedaan om gebruik te maken bulkrequests en een alternatief loggingframework.
In \cref{impact-db} hebben we ook gezien dat de databankinteracties een grote negatieve impact hebben op de uitvoeringstijd.
Omdat we daarvoor geen oplossing hebben geïmplementeerd, moeten we het stellen bij het vergelijken van de uitvoeringstijd met en zonder databankinteracties.

\subsubsection{Meetresultaten}

De uitvoeringstijd van de \nwmretriever{} op grote schaal hebben we al gemeten in de paragraaf over de impact van de databankinteracties,
dus nemen we die resultaten er weer bij.

\begin{table}[h]
\centering
\begin{tabular}{@{}ccrrr@{}}
\toprule
\multicolumn{1}{l}{Nodes} & \multicolumn{1}{l}{Versie} & Insert & Uitvoeringstijd (s) & Factor nieuw vs oud \\ \midrule
\multirow{4}{*}{100}      & \multirow{2}{*}{Oud}       & Ja     & 1100.418            &                     \\
                          &                            & Nee    & 125.820             &                     \\
                          & \multirow{2}{*}{Nieuw}     & Ja     & 1051.373            & 1.05                \\
                          &                            & Nee    & 17.229              & 7.30                \\ \bottomrule
\end{tabular}
\caption{Uitvoeringstijd van de \nwmretriever{} op grote schaal}
\label{tabel-uitvoeringstijd-vwall}
\end{table}

In die paragraaf hebben we al gezien dat het verschil tussen de oude versie en de nieuwe slechts 5\% bedraagt
als de gegevens in de databank weggeschreven moeten worden.
Wanneer dat niet het geval is, is de nieuwe versie ruim zever keer sneller dan de oude!
Het is dus van absoluut belang dat dit probleem aangepakt wordt, of er gebruik gemaakt wordt van een SSD om de databank op te slaan
Natuurlijk zal een alternatieve implementatie niet exact 7,3 keer sneller zijn, maar het geeft wel een goed idee
van hoeveel sneller de \nwmretriever{} zou kunnen gaan.

\subsubsection{Conclusie}

Op voorwaarde dat het probleem met de databankinteracties aangepakt wordt kunnen we besluiten dat de gemaakte verbeteringen
al een zeer positieve invloed hebben gehad op de uitvoeringstijd van de \nwmretriever{} op grote schaal.
De kleine uitvoeringstijd is echter niet het enige criterium om te beslissen of de retriever goed schaalbaar is:
ook met andere resources moet goed omgegaan worden, zoals CPU, geheugen en bandbreedte.
Die zaken onderzoeken we in de volgende paragrafen.


\subsection{Benchmarks bandbreedte}

\todo[inline]{\textbf{Een} machine? 50, 100 machines?}

\todo[inline]{Een toestel -> Bytes/sec ~= Packets/sec \\
Gecombineerde grafiek? Bps en packets?}

\subsubsection{Een toestel}


\subsubsection{SNMP Walk versus SNMP Bulk Requests}

\subsubsection{Invloed aantal ondervraagde nodes}

\todo[inline]{Verwijs voor dip in bandbreedte bij groot aantal nodes (>50) naar sectie CPU gebruik.}

\subsection{Benchmarks CPU-gebruik}

\todo[inline]{Onderzoek waarom verkeer \& CPU-verbruik dippen voor het einde (aantal threads daalt).}

\subsection{Benchmarks geheugenverbruik}